{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPor defecto, keras no tira de GPU\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "'''\n",
    "Por defecto, keras no tira de GPU\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcAElEQVR4nO3df2zU9R3H8dfxo2eR9rDU9tpRsKDCJlIjg65BGErTUhMjyBZ/JuAMRCxmgL9SoyC4rA4zx3RMs0SpJuIPNn5Es5FhsSVuLQaEEXR2tKlSAi3K1rtSpDD62R+EGydF+B7Xvnvl+UgusXf37r333aVPv9716nPOOQEA0MP6WS8AALg0ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBigPUC39bZ2akDBw4oJSVFPp/Peh0AgEfOObW1tSk7O1v9+p37PKfXBejAgQPKycmxXgMAcJGampo0bNiwc97e6wKUkpIi6dTiqampxtsAALwKh8PKycmJ/Dw/l24L0KpVq/T888+rublZeXl5eumllzRx4sTzzp3+z26pqakECAAS2PleRumWNyG88847Wrx4sZYuXapPPvlEeXl5Ki4u1qFDh7rj4QAACahbAvTCCy9o7ty5uv/++/WDH/xAr7zyigYNGqTXXnutOx4OAJCA4h6g48ePa8eOHSosLPz/g/Trp8LCQtXU1Jx1/46ODoXD4agLAKDvi3uAvv76a508eVKZmZlR12dmZqq5ufms+5eXlysQCEQuvAMOAC4N5r+IWlZWplAoFLk0NTVZrwQA6AFxfxdcenq6+vfvr5aWlqjrW1paFAwGz7q/3++X3++P9xoAgF4u7mdASUlJGj9+vCorKyPXdXZ2qrKyUgUFBfF+OABAguqW3wNavHixZs+erR/+8IeaOHGiVq5cqfb2dt1///3d8XAAgATULQG688479dVXX2nJkiVqbm7WDTfcoE2bNp31xgQAwKXL55xz1kucKRwOKxAIKBQK8UkIAJCALvTnuPm74AAAlyYCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxADrBYDepLOz0/NMR0dHN2wSH6+//npMc+3t7Z5nPvvsM88zK1eu9Dzz5JNPep753e9+53lGkpKTkz3P/PrXv/Y8M3/+fM8zfQFnQAAAEwQIAGAi7gF65pln5PP5oi5jxoyJ98MAABJct7wGdN111+mDDz74/4MM4KUmAEC0binDgAEDFAwGu+NbAwD6iG55DWjv3r3Kzs7WyJEjde+992rfvn3nvG9HR4fC4XDUBQDQ98U9QPn5+aqoqNCmTZv08ssvq7GxUZMnT1ZbW1uX9y8vL1cgEIhccnJy4r0SAKAXinuASkpK9NOf/lTjxo1TcXGx/vznP6u1tVXvvvtul/cvKytTKBSKXJqamuK9EgCgF+r2dwcMGTJE1157rerr67u83e/3y+/3d/caAIBeptt/D+jIkSNqaGhQVlZWdz8UACCBxD1Ajz76qKqrq/XFF1/o73//u2bOnKn+/fvr7rvvjvdDAQASWNz/E9z+/ft199136/Dhw7ryyit10003qba2VldeeWW8HwoAkMDiHqC333473t8SvVQoFPI8c/LkSc8z//jHPzzP/PWvf/U8I0mtra2eZ/7whz/E9Fh9zVVXXeV55pFHHvE88+qrr3qeCQQCnmckafLkyZ5nbrnllpge61LEZ8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZ8zjlnvcSZwuGwAoGAQqGQUlNTrde5JOzfvz+muRtuuMHzzH/+85+YHgs9q18/7/9uunnzZs8zycnJnmdikZGREdPc4MGDPc/wyf8X/nOcMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGC9AOwNHTo0prnMzEzPM3wa9ilFRUWeZ2L5/2ndunWeZyTJ7/d7npk6dWpMj4VLF2dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJPowUSk5OjmmuoqLC88wf//hHzzMFBQWeZ2bNmuV5JlY33XST55mNGzd6nklKSvI809zc7HlGkn7729/GNAd4wRkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC55xz1kucKRwOKxAIKBQKKTU11XodxFlHR4fnmVg+hPPJJ5/0PCNJK1as8Dzz4Ycfep6ZMmWK5xkgUVzoz3HOgAAAJggQAMCE5wBt3bpVt912m7Kzs+Xz+bRhw4ao251zWrJkibKyspScnKzCwkLt3bs3XvsCAPoIzwFqb29XXl6eVq1a1eXtK1as0IsvvqhXXnlF27Zt0+WXX67i4mIdO3bsopcFAPQdnv8iaklJiUpKSrq8zTmnlStX6qmnntLtt98uSXrjjTeUmZmpDRs26K677rq4bQEAfUZcXwNqbGxUc3OzCgsLI9cFAgHl5+erpqamy5mOjg6Fw+GoCwCg74trgE7//fnMzMyo6zMzM8/5t+nLy8sVCAQil5ycnHiuBADopczfBVdWVqZQKBS5NDU1Wa8EAOgBcQ1QMBiUJLW0tERd39LSErnt2/x+v1JTU6MuAIC+L64Bys3NVTAYVGVlZeS6cDisbdu2qaCgIJ4PBQBIcJ7fBXfkyBHV19dHvm5sbNSuXbuUlpam4cOHa+HChfrFL36ha665Rrm5uXr66aeVnZ2tGTNmxHNvAECC8xyg7du36+abb458vXjxYknS7NmzVVFRoccff1zt7e2aN2+eWltbddNNN2nTpk267LLL4rc1ACDheQ7Q1KlT9V2fX+rz+bR8+XItX778ohZD3+T3+3vkca644ooeeRxJevHFFz3PTJ482fOMz+fzPAP0ZubvggMAXJoIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvOnYQOJYOHChTHNffzxx55n1q9f73nm008/9TwzduxYzzNAb8YZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwuecc9ZLnCkcDisQCCgUCik1NdV6HVxi/v3vf3ueGTVqlOeZtLQ0zzMzZszwPDNp0iTPM5I0c+ZMzzM+ny+mx0Lfc6E/xzkDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM8GGkwEX6+OOPPc9Mnz7d80woFPI8E6vXXnvN88ysWbM8zwwePNjzDHo/PowUANCrESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmBlgvACS6iRMnep759NNPPc8sWrTI88zatWs9z0jSz372M88zDQ0Nnmcee+wxzzMpKSmeZ9A7cQYEADBBgAAAJjwHaOvWrbrtttuUnZ0tn8+nDRs2RN0+Z84c+Xy+qEssf/sEANC3eQ5Qe3u78vLytGrVqnPeZ/r06Tp48GDk8tZbb13UkgCAvsfzmxBKSkpUUlLynffx+/0KBoMxLwUA6Pu65TWgqqoqZWRkaPTo0Zo/f74OHz58zvt2dHQoHA5HXQAAfV/cAzR9+nS98cYbqqys1K9+9StVV1erpKREJ0+e7PL+5eXlCgQCkUtOTk68VwIA9EJx/z2gu+66K/LP119/vcaNG6dRo0apqqpK06ZNO+v+ZWVlWrx4ceTrcDhMhADgEtDtb8MeOXKk0tPTVV9f3+Xtfr9fqampURcAQN/X7QHav3+/Dh8+rKysrO5+KABAAvH8n+COHDkSdTbT2NioXbt2KS0tTWlpaVq2bJlmzZqlYDCohoYGPf7447r66qtVXFwc18UBAInNc4C2b9+um2++OfL16ddvZs+erZdfflm7d+/W66+/rtbWVmVnZ6uoqEjPPvus/H5//LYGACQ8n3POWS9xpnA4rEAgoFAoxOtBwBmOHTvmeaa2tjamxyosLPQ8E8uPkp/85CeeZ9555x3PM+hZF/pznM+CAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAk+DRvAWWL58yn//e9/Pc8MGOD5L8Jo9+7dnmdGjx7teQax49OwAQC9GgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvsnAQK4aAcOHPA8s27dOs8zNTU1nmek2D5YNBYTJkzwPHPttdd2wyawwBkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCDyMFzvDVV195nlm1apXnmdWrV3ue2b9/v+eZntS/f3/PM1dddZXnGZ/P53kGvRNnQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACT6MFL3ekSNHPM+89957MT3W8uXLPc/861//iumxerNbbrnF88xzzz3neWb8+PGeZ9B3cAYEADBBgAAAJjwFqLy8XBMmTFBKSooyMjI0Y8YM1dXVRd3n2LFjKi0t1dChQzV48GDNmjVLLS0tcV0aAJD4PAWourpapaWlqq2t1ebNm3XixAkVFRWpvb09cp9Fixbpvffe09q1a1VdXa0DBw7ojjvuiPviAIDE5ulNCJs2bYr6uqKiQhkZGdqxY4emTJmiUCikV199VWvWrIm8iLl69Wp9//vfV21trX70ox/Fb3MAQEK7qNeAQqGQJCktLU2StGPHDp04cUKFhYWR+4wZM0bDhw9XTU1Nl9+jo6ND4XA46gIA6PtiDlBnZ6cWLlyoSZMmaezYsZKk5uZmJSUlaciQIVH3zczMVHNzc5ffp7y8XIFAIHLJycmJdSUAQAKJOUClpaXas2eP3n777YtaoKysTKFQKHJpamq6qO8HAEgMMf0i6oIFC/T+++9r69atGjZsWOT6YDCo48ePq7W1NeosqKWlRcFgsMvv5ff75ff7Y1kDAJDAPJ0BOee0YMECrV+/Xlu2bFFubm7U7ePHj9fAgQNVWVkZua6urk779u1TQUFBfDYGAPQJns6ASktLtWbNGm3cuFEpKSmR13UCgYCSk5MVCAT0wAMPaPHixUpLS1NqaqoefvhhFRQU8A44AEAUTwF6+eWXJUlTp06Nun716tWaM2eOJOk3v/mN+vXrp1mzZqmjo0PFxcX6/e9/H5dlAQB9h88556yXOFM4HFYgEFAoFFJqaqr1OvgOZ/4C8oWK5U0m9913n+eZnTt3ep7p7YqKijzPLFu2LKbHmjBhgucZn88X02Oh77nQn+N8FhwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMxPQXUdF7ffPNN55nFi5cGNNjffTRR55nPv/885geqze79dZbPc8sWbLE88wNN9zgeWbgwIGeZ4CewhkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCDyPtIV988YXnmV/+8peeZz744APPM19++aXnmd5u0KBBMc09++yznmceeughzzNJSUmeZ4C+hjMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEH0baQ/70pz95nnn11Ve7YZP4ufHGGz3P3H333Z5nBgzw/jSdN2+e5xlJuuyyy2KaA+AdZ0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAmfc85ZL3GmcDisQCCgUCik1NRU63UAAB5d6M9xzoAAACYIEADAhKcAlZeXa8KECUpJSVFGRoZmzJihurq6qPtMnTpVPp8v6vLggw/GdWkAQOLzFKDq6mqVlpaqtrZWmzdv1okTJ1RUVKT29vao+82dO1cHDx6MXFasWBHXpQEAic/Tn5rctGlT1NcVFRXKyMjQjh07NGXKlMj1gwYNUjAYjM+GAIA+6aJeAwqFQpKktLS0qOvffPNNpaena+zYsSorK9PRo0fP+T06OjoUDoejLgCAvs/TGdCZOjs7tXDhQk2aNEljx46NXH/PPfdoxIgRys7O1u7du/XEE0+orq5O69at6/L7lJeXa9myZbGuAQBIUDH/HtD8+fP1l7/8RR999JGGDRt2zvtt2bJF06ZNU319vUaNGnXW7R0dHero6Ih8HQ6HlZOTw+8BAUCCutDfA4rpDGjBggV6//33tXXr1u+MjyTl5+dL0jkD5Pf75ff7Y1kDAJDAPAXIOaeHH35Y69evV1VVlXJzc887s2vXLklSVlZWTAsCAPomTwEqLS3VmjVrtHHjRqWkpKi5uVmSFAgElJycrIaGBq1Zs0a33nqrhg4dqt27d2vRokWaMmWKxo0b1y3/AwAAicnTa0A+n6/L61evXq05c+aoqalJ9913n/bs2aP29nbl5ORo5syZeuqppy749Rw+Cw4AElu3vAZ0vlbl5OSourray7cEAFyi+Cw4AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJAdYLfJtzTpIUDoeNNwEAxOL0z+/TP8/PpdcFqK2tTZKUk5NjvAkA4GK0tbUpEAic83afO1+ielhnZ6cOHDiglJQU+Xy+qNvC4bBycnLU1NSk1NRUow3tcRxO4TicwnE4heNwSm84Ds45tbW1KTs7W/36nfuVnl53BtSvXz8NGzbsO++Tmpp6ST/BTuM4nMJxOIXjcArH4RTr4/BdZz6n8SYEAIAJAgQAMJFQAfL7/Vq6dKn8fr/1KqY4DqdwHE7hOJzCcTglkY5Dr3sTAgDg0pBQZ0AAgL6DAAEATBAgAIAJAgQAMJEwAVq1apWuuuoqXXbZZcrPz9fHH39svVKPe+aZZ+Tz+aIuY8aMsV6r223dulW33XabsrOz5fP5tGHDhqjbnXNasmSJsrKylJycrMLCQu3du9dm2W50vuMwZ86cs54f06dPt1m2m5SXl2vChAlKSUlRRkaGZsyYobq6uqj7HDt2TKWlpRo6dKgGDx6sWbNmqaWlxWjj7nEhx2Hq1KlnPR8efPBBo427lhABeuedd7R48WItXbpUn3zyifLy8lRcXKxDhw5Zr9bjrrvuOh08eDBy+eijj6xX6nbt7e3Ky8vTqlWrurx9xYoVevHFF/XKK69o27Ztuvzyy1VcXKxjx4718Kbd63zHQZKmT58e9fx46623enDD7lddXa3S0lLV1tZq8+bNOnHihIqKitTe3h65z6JFi/Tee+9p7dq1qq6u1oEDB3THHXcYbh1/F3IcJGnu3LlRz4cVK1YYbXwOLgFMnDjRlZaWRr4+efKky87OduXl5YZb9bylS5e6vLw86zVMSXLr16+PfN3Z2emCwaB7/vnnI9e1trY6v9/v3nrrLYMNe8a3j4Nzzs2ePdvdfvvtJvtYOXTokJPkqqurnXOn/r8fOHCgW7t2beQ+//znP50kV1NTY7Vmt/v2cXDOuR//+Mfu5z//ud1SF6DXnwEdP35cO3bsUGFhYeS6fv36qbCwUDU1NYab2di7d6+ys7M1cuRI3Xvvvdq3b5/1SqYaGxvV3Nwc9fwIBALKz8+/JJ8fVVVVysjI0OjRozV//nwdPnzYeqVuFQqFJElpaWmSpB07dujEiRNRz4cxY8Zo+PDhffr58O3jcNqbb76p9PR0jR07VmVlZTp69KjFeufU6z6M9Nu+/vprnTx5UpmZmVHXZ2Zm6vPPPzfaykZ+fr4qKio0evRoHTx4UMuWLdPkyZO1Z88epaSkWK9norm5WZK6fH6cvu1SMX36dN1xxx3Kzc1VQ0ODnnzySZWUlKimpkb9+/e3Xi/uOjs7tXDhQk2aNEljx46VdOr5kJSUpCFDhkTdty8/H7o6DpJ0zz33aMSIEcrOztbu3bv1xBNPqK6uTuvWrTPcNlqvDxD+r6SkJPLP48aNU35+vkaMGKF3331XDzzwgOFm6A3uuuuuyD9ff/31GjdunEaNGqWqqipNmzbNcLPuUVpaqj179lwSr4N+l3Mdh3nz5kX++frrr1dWVpamTZumhoYGjRo1qqfX7FKv/09w6enp6t+//1nvYmlpaVEwGDTaqncYMmSIrr32WtXX11uvYub0c4Dnx9lGjhyp9PT0Pvn8WLBggd5//319+OGHUX++JRgM6vjx42ptbY26f199PpzrOHQlPz9fknrV86HXBygpKUnjx49XZWVl5LrOzk5VVlaqoKDAcDN7R44cUUNDg7KysqxXMZObm6tgMBj1/AiHw9q2bdsl//zYv3+/Dh8+3KeeH845LViwQOvXr9eWLVuUm5sbdfv48eM1cODAqOdDXV2d9u3b16eeD+c7Dl3ZtWuXJPWu54P1uyAuxNtvv+38fr+rqKhwn332mZs3b54bMmSIa25utl6tRz3yyCOuqqrKNTY2ur/97W+usLDQpaenu0OHDlmv1q3a2trczp073c6dO50k98ILL7idO3e6L7/80jnn3HPPPeeGDBniNm7c6Hbv3u1uv/12l5ub67755hvjzePru45DW1ube/TRR11NTY1rbGx0H3zwgbvxxhvdNddc444dO2a9etzMnz/fBQIBV1VV5Q4ePBi5HD16NHKfBx980A0fPtxt2bLFbd++3RUUFLiCggLDrePvfMehvr7eLV++3G3fvt01Nja6jRs3upEjR7opU6YYbx4tIQLknHMvvfSSGz58uEtKSnITJ050tbW11iv1uDvvvNNlZWW5pKQk973vfc/deeedrr6+3nqtbvfhhx86SWddZs+e7Zw79Vbsp59+2mVmZjq/3++mTZvm6urqbJfuBt91HI4ePeqKiorclVde6QYOHOhGjBjh5s6d2+f+Ja2r//2S3OrVqyP3+eabb9xDDz3krrjiCjdo0CA3c+ZMd/DgQbulu8H5jsO+ffvclClTXFpamvP7/e7qq692jz32mAuFQraLfwt/jgEAYKLXvwYEAOibCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT/wOZOh12/MH8BAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays). Aplano a una dimension cada imagen.\n",
    "# Escalamos ya que vamos a usar gradient descent, y le afecta mucho la escala de las features.\n",
    "# Ejecutar esta celda solo una vez. Sino reescalará\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Reserve 10,000 samples for validation. Entraran dentro del modelo para validar. No es validacion cruzada\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una manera de declarar la red neuronal\n",
    "\n",
    "# Siempre hay que declarar la capa sequential para empezar a declarar la red\n",
    "# Se trata de la API sequential\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Flatten, aplana en un unico vector. Y especificamos el tamaño de la entrada\n",
    "# Es como si hiciese un .reshape(-1, 28*28)\n",
    "# \"kernel_initializer\" o \"bias_initializer\" No lo usamos pero seria para inicializar los pesos de otra manera\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Capas de la red. Dense es la capa de neuronas. Necesitamos numero y activacion\n",
    "model.add(keras.layers.Dense(units = 300, # Numero de neuronas de la capa\n",
    "                             activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(100,\n",
    "                             activation='relu'))\n",
    "\n",
    "# Capa de salida, con tamaño del número de clases\n",
    "# Suele ir aqui un softmax. Para multiclase guay. Si es binaria -> sigmoide\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "]\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x000001DCE0C73808>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x1dce3038208>,\n",
       " <keras.layers.core.dense.Dense at 0x1dce0c73808>,\n",
       " <keras.layers.core.dense.Dense at 0x1dce0d51688>,\n",
       " <keras.layers.core.dense.Dense at 0x1dce0d49108>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()\n",
    "\n",
    "# 784 features (pixeles de las imagenes) x 300 neuronas\n",
    "# Los pesos están inicializados aleatoriamente\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la configuración del entrenamiento (optimizador, pérdida, métricas):\n",
    "model.compile(\n",
    "    # Stocastic gradient descent. El algoritmo para minimizar la loss function\n",
    "    # El stocastic va haciendo muestreo en cada evaluacion, no usa todo el dataset\n",
    "    # Podemos modificar el learning rate(0.01 por defecto) mediante el parametro lr\n",
    "    optimizer=keras.optimizers.SGD(),  # Optimizer\n",
    "    \n",
    "    \n",
    "    # Loss function to minimize\n",
    "    # sparse_categorical_crossentropy cuando tenemos un label en nuna columna\n",
    "    # Si lo tuviesemos en varias tipo dummy, cogeriamos categorical_crossentropy\n",
    "    # binary_crossentropy si es una neurona, clasi binario\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(optimizer=\"sgd\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "# La primera hidden layer tiene 784 entradas x 300 salidas\n",
    "# Son los 235500 params = 783x300 + 300 (bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1293 - accuracy: 0.9636 - val_loss: 0.1350 - val_accuracy: 0.9636\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1227 - accuracy: 0.9655 - val_loss: 0.1389 - val_accuracy: 0.9605\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1179 - accuracy: 0.9669 - val_loss: 0.1266 - val_accuracy: 0.9650\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1122 - accuracy: 0.9689 - val_loss: 0.1229 - val_accuracy: 0.9647\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1075 - accuracy: 0.9697 - val_loss: 0.1192 - val_accuracy: 0.9663\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1027 - accuracy: 0.9714 - val_loss: 0.1187 - val_accuracy: 0.9670\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0986 - accuracy: 0.9728 - val_loss: 0.1148 - val_accuracy: 0.9672\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0943 - accuracy: 0.9741 - val_loss: 0.1135 - val_accuracy: 0.9677\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0910 - accuracy: 0.9746 - val_loss: 0.1106 - val_accuracy: 0.9678\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0871 - accuracy: 0.9763 - val_loss: 0.1075 - val_accuracy: 0.9684\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0837 - accuracy: 0.9771 - val_loss: 0.1075 - val_accuracy: 0.9686\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0808 - accuracy: 0.9777 - val_loss: 0.1038 - val_accuracy: 0.9696\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0777 - accuracy: 0.9794 - val_loss: 0.1032 - val_accuracy: 0.9716\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0748 - accuracy: 0.9797 - val_loss: 0.1059 - val_accuracy: 0.9692\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0724 - accuracy: 0.9806 - val_loss: 0.0997 - val_accuracy: 0.9712\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0698 - accuracy: 0.9813 - val_loss: 0.0973 - val_accuracy: 0.9720\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0672 - accuracy: 0.9822 - val_loss: 0.0964 - val_accuracy: 0.9720\n",
      "Epoch 18/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0649 - accuracy: 0.9825 - val_loss: 0.0954 - val_accuracy: 0.9716\n",
      "Epoch 19/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0627 - accuracy: 0.9838 - val_loss: 0.0949 - val_accuracy: 0.9728\n",
      "Epoch 20/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0607 - accuracy: 0.9843 - val_loss: 0.0940 - val_accuracy: 0.9721\n",
      "Epoch 21/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0585 - accuracy: 0.9847 - val_loss: 0.0948 - val_accuracy: 0.9720\n",
      "Epoch 22/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0568 - accuracy: 0.9853 - val_loss: 0.0911 - val_accuracy: 0.9734\n",
      "Epoch 23/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0548 - accuracy: 0.9862 - val_loss: 0.0901 - val_accuracy: 0.9740\n",
      "Epoch 24/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0531 - accuracy: 0.9864 - val_loss: 0.0909 - val_accuracy: 0.9726\n",
      "Epoch 25/30\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0514 - accuracy: 0.9868 - val_loss: 0.0888 - val_accuracy: 0.9734\n",
      "Epoch 26/30\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0498 - accuracy: 0.9876 - val_loss: 0.0885 - val_accuracy: 0.9735\n",
      "Epoch 27/30\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0482 - accuracy: 0.9882 - val_loss: 0.0881 - val_accuracy: 0.9729\n",
      "Epoch 28/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0468 - accuracy: 0.9883 - val_loss: 0.0860 - val_accuracy: 0.9742\n",
      "Epoch 29/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0453 - accuracy: 0.9887 - val_loss: 0.0869 - val_accuracy: 0.9746\n",
      "Epoch 30/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0441 - accuracy: 0.9893 - val_loss: 0.0856 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEn el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\\nSi vemos que ya no baja mas, no serán necesarias tantas epochs.\\nImprimera tantas lineas como epochs hayamos puesto\\n\\nTampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\\nUtil para datasets desbalanceados.\\n\\nEl loss que muestra es el categoricalcrossentropy\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con un batch_size de 64 imágenes por cada iteración, 10 epochs y especificando cuál es el conjunto de validación.\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64, # numero de muestras empleadas en el entrenamiento de SGD\n",
    "    epochs=30, # 1 por defecto. Insuficiente. Numero de vueltas del backpropagation\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    # En vez de validation data podemos usar el argumento validation_split=0.1\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1264 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9628\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9665 - val_loss: 0.1304 - val_sparse_categorical_accuracy: 0.9641\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1148 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.1274 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9654\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1051 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.1198 - val_sparse_categorical_accuracy: 0.9656\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9721 - val_loss: 0.1177 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9674\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1119 - val_sparse_categorical_accuracy: 0.9680\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9677\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1087 - val_sparse_categorical_accuracy: 0.9693\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1059 - val_sparse_categorical_accuracy: 0.9698\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.1049 - val_sparse_categorical_accuracy: 0.9701\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9707\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9716\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1008 - val_sparse_categorical_accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de29fb2640>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 30, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.129264697432518,\n",
       "  0.12265979498624802,\n",
       "  0.11786822974681854,\n",
       "  0.11224333941936493,\n",
       "  0.10753761976957321,\n",
       "  0.10271965712308884,\n",
       "  0.09863901138305664,\n",
       "  0.0943135917186737,\n",
       "  0.09100257605314255,\n",
       "  0.08705633878707886,\n",
       "  0.08374488353729248,\n",
       "  0.08082227408885956,\n",
       "  0.07771110534667969,\n",
       "  0.07484003156423569,\n",
       "  0.0723779946565628,\n",
       "  0.0697750598192215,\n",
       "  0.06715936213731766,\n",
       "  0.06490251421928406,\n",
       "  0.06267329305410385,\n",
       "  0.06072991341352463,\n",
       "  0.05853794515132904,\n",
       "  0.05675922706723213,\n",
       "  0.05484723672270775,\n",
       "  0.05309807136654854,\n",
       "  0.05136619508266449,\n",
       "  0.04981256276369095,\n",
       "  0.04822874069213867,\n",
       "  0.04675278440117836,\n",
       "  0.045250359922647476,\n",
       "  0.044055454432964325],\n",
       " 'accuracy': [0.9636399745941162,\n",
       "  0.965499997138977,\n",
       "  0.9668999910354614,\n",
       "  0.9688599705696106,\n",
       "  0.9696999788284302,\n",
       "  0.9713799953460693,\n",
       "  0.9728000164031982,\n",
       "  0.9740800261497498,\n",
       "  0.9746000170707703,\n",
       "  0.9763000011444092,\n",
       "  0.9771400094032288,\n",
       "  0.9777200222015381,\n",
       "  0.979420006275177,\n",
       "  0.9796800017356873,\n",
       "  0.9805799722671509,\n",
       "  0.9812800288200378,\n",
       "  0.9821599721908569,\n",
       "  0.9825000166893005,\n",
       "  0.983780026435852,\n",
       "  0.9842600226402283,\n",
       "  0.9846799969673157,\n",
       "  0.985319972038269,\n",
       "  0.9861999750137329,\n",
       "  0.9864199757575989,\n",
       "  0.9868199825286865,\n",
       "  0.9876400232315063,\n",
       "  0.9882000088691711,\n",
       "  0.9883000254631042,\n",
       "  0.9886800050735474,\n",
       "  0.9893400073051453],\n",
       " 'val_loss': [0.135036900639534,\n",
       "  0.1388753056526184,\n",
       "  0.12657375633716583,\n",
       "  0.12288918346166611,\n",
       "  0.11915262788534164,\n",
       "  0.11867722123861313,\n",
       "  0.11483988165855408,\n",
       "  0.11347699165344238,\n",
       "  0.11061407625675201,\n",
       "  0.10746750235557556,\n",
       "  0.10749892890453339,\n",
       "  0.10384093970060349,\n",
       "  0.10318298637866974,\n",
       "  0.10590483248233795,\n",
       "  0.09970002621412277,\n",
       "  0.09729428589344025,\n",
       "  0.09642292559146881,\n",
       "  0.09541475027799606,\n",
       "  0.09494191408157349,\n",
       "  0.09402783215045929,\n",
       "  0.0948142558336258,\n",
       "  0.09105619788169861,\n",
       "  0.09012845158576965,\n",
       "  0.09090114384889603,\n",
       "  0.08877971023321152,\n",
       "  0.0884915292263031,\n",
       "  0.08806195855140686,\n",
       "  0.0859709307551384,\n",
       "  0.08690686523914337,\n",
       "  0.08555804938077927],\n",
       " 'val_accuracy': [0.9635999798774719,\n",
       "  0.9605000019073486,\n",
       "  0.9649999737739563,\n",
       "  0.9646999835968018,\n",
       "  0.9663000106811523,\n",
       "  0.9670000076293945,\n",
       "  0.967199981212616,\n",
       "  0.9677000045776367,\n",
       "  0.9678000211715698,\n",
       "  0.9684000015258789,\n",
       "  0.9685999751091003,\n",
       "  0.9696000218391418,\n",
       "  0.9715999960899353,\n",
       "  0.9692000150680542,\n",
       "  0.9711999893188477,\n",
       "  0.972000002861023,\n",
       "  0.972000002861023,\n",
       "  0.9715999960899353,\n",
       "  0.9728000164031982,\n",
       "  0.972100019454956,\n",
       "  0.972000002861023,\n",
       "  0.9733999967575073,\n",
       "  0.9739999771118164,\n",
       "  0.972599983215332,\n",
       "  0.9733999967575073,\n",
       "  0.9735000133514404,\n",
       "  0.9728999733924866,\n",
       "  0.9742000102996826,\n",
       "  0.9746000170707703,\n",
       "  0.9750000238418579]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Podemos ver como evoluciona el entrenamiento, en funcion de los epochs\n",
    "# Validacion y training estan muy cerca, no hay overfitting!\n",
    "# Todavia no ha acabado de coverger ya que el loss en validacion sigue bajando,\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9699\n",
      "test loss, test acc: [0.09595837444067001, 0.9699000120162964]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el \"score\" a partir del conjunto de test\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "\n",
    "# Metodo evaluate para que nos de el error vs las metricas elegidas en la funcion compile\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.001, 0.001, 0.   , 0.   , 0.   , 0.998, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ojo aqui viene slicing xq presupone que le entran varios inputs\n",
    "Nos da las probabilidades de pertenecer a una clase u otra.\n",
    "'''\n",
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 973us/step - loss: 1.0690 - val_loss: 0.5387\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.5454 - val_loss: 0.4826\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.5084 - val_loss: 0.4644\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.4627 - val_loss: 0.4409\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.4611 - val_loss: 0.4356\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.4628 - val_loss: 0.4323\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.4393 - val_loss: 0.4233\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.4332 - val_loss: 0.4157\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4146\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4081\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4033\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.4148 - val_loss: 0.4010\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.4177 - val_loss: 0.3999\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.4069 - val_loss: 0.3912\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 784us/step - loss: 0.4013 - val_loss: 0.3925\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3996 - val_loss: 0.3865\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.3950 - val_loss: 0.3824\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.4034 - val_loss: 0.3867\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.4151 - val_loss: 0.4188\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.4003 - val_loss: 0.3915\n",
      "162/162 [==============================] - 0s 585us/step - loss: 0.3956\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    # No hace falta capa de flatten. No hay que aplanar ninguna imagen\n",
    "    keras.layers.Dense(30, activation=\"relu\",\n",
    "                       input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # una unica neurona de salida\n",
    "    # Sin fun de activa. ReLu no iria mal si el output es positivo. Sigmoide si esta acotado.\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3094\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 779us/step - loss: 0.3074\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3076\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3089\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3057\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3059\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3051\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3048\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.3067\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3037\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3335\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.3203\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3221\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3169\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3200\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3153\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3141\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3038 - val_loss: 0.3389\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3169\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3433\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.3198\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3103 - val_loss: 0.3228\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.3201\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.3202\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3065 - val_loss: 0.3236\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 894us/step - loss: 0.3046 - val_loss: 0.3197\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.3230\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3051 - val_loss: 0.3193\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3038 - val_loss: 0.3147\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3031 - val_loss: 0.3164\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3205\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3173\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3162\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.3055 - val_loss: 0.3269\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.3199\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 886us/step - loss: 0.3059 - val_loss: 0.3199\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3065 - val_loss: 0.3309\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 775us/step - loss: 0.3048 - val_loss: 0.3232\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "10 esta bien. Lo pondemos a 5 para el ejercicio\n",
    "¿Qué considera como dejar de mejorar? parametros min_delta y baseline\n",
    "'''\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, \n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crea este directorio\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Guarda una carpeta nueva con la fecha de la ejecucion\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/363 [..............................] - ETA: 0s - loss: 0.1658WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0202s). Check your callbacks.\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3417\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3287 - val_loss: 0.3366\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.3332\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.3341\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3239 - val_loss: 0.3361\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3277 - val_loss: 0.3330\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3233 - val_loss: 0.3274\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.3234 - val_loss: 0.3270\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3201 - val_loss: 0.3265\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3207 - val_loss: 0.3271\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 0s 880us/step - loss: 0.3207 - val_loss: 0.3295\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3382\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3333\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3256 - val_loss: 0.3392\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3226 - val_loss: 0.3339\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3236 - val_loss: 0.3310\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.3252 - val_loss: 0.3512\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3208 - val_loss: 0.3354\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3247\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3236\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3173 - val_loss: 0.3908\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3408\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.3272\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3352\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3404\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.3181 - val_loss: 0.3265\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3146 - val_loss: 0.3216\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3157 - val_loss: 0.3221\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 0s 894us/step - loss: 0.3127 - val_loss: 0.3262\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3126 - val_loss: 0.3308\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3135 - val_loss: 0.3254\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3117 - val_loss: 0.3239\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3117 - val_loss: 0.3292\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.3272\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3112 - val_loss: 0.3182\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3095 - val_loss: 0.3241\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3183\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3142 - val_loss: 0.3277\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3221\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3232\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.3242\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3287\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.3093 - val_loss: 0.3203\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3186\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.3184 - val_loss: 0.3261\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3231\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.3238\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3092 - val_loss: 0.3193\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3211\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.3207\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fc21116b3e4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--logdir=./my_logs --port=6006'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2324\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2325\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2326\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2327\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\notebook.py\u001b[0m in \u001b[0;36m_start_magic\u001b[1;34m(line)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_start_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;34m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\notebook.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(args_string)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mparsed_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshlex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[0mstart_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStartLaunched\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(arguments, timeout)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[0mend_time_seconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_time_seconds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend_time_seconds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoll_interval_seconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[0msubprocess_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msubprocess_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Para lanzarlo desde el jupyter notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "Para lanzarlo desde el terminal, hay que estar en la carpeta de los logs\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
