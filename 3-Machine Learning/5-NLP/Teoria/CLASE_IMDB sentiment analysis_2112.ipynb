{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis\n",
    "\n",
    "The data is split evenly with 25k reviews intended for training and 25k for testing your classifier. Moreover, each set has 12.5k positive and 12.5k negative reviews.\n",
    "\n",
    "IMDb lets users rate movies on a scale from 1 to 10. To label these reviews the curator of the data labeled anything with ≤ 4 stars as negative and anything with ≥ 7 stars as positive. Reviews with 5 or 6 stars were left out.\n",
    "\n",
    "**Import the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c24add7db0417a9781174f371b80bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5390c5a1b246929456999c16e9e491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Movie Review Dataset.\n",
      "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n",
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=2, names=['neg', 'pos'], id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "ds_builder = load_dataset_builder(\"imdb\")\n",
    "\n",
    "# Inspect dataset description\n",
    "print(ds_builder.info.description)\n",
    "\n",
    "# Inspect dataset features\n",
    "print(ds_builder.info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to C:\\Users\\alber\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0481db34074c473c9e2cc334727feb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055f186f9d9e496ebe63285b8cf296b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a659b1369d4e03b28016a037b96fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4ef0b042ee4242bc497b2f251a5b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to C:\\Users\\alber\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\alber\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\imdb\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1 (last modified on Sun Jun 19 14:33:12 2022) since it couldn't be found locally at imdb., or remotely on the Hugging Face Hub.\n",
      "Reusing dataset imdb (C:\\Users\\alber\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "reviews_train = load_dataset(\"imdb\", split=\"train\")\n",
    "reviews_test = load_dataset(\"imdb\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_train = []\n",
    "# for line in open('C:/Users/Daney/Desktop/Archivos/Material/Databases/NLP/IMDB/full_train.txt', 'r', encoding='latin1'):\n",
    "    \n",
    "#     reviews_train.append(line.strip())\n",
    "    \n",
    "# reviews_test = []\n",
    "# for line in open('C:/Users/Daney/Desktop/Archivos/Material/Databases/NLP/IMDB/full_test.txt', 'r', encoding='latin1'):\n",
    "    \n",
    "#     reviews_test.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = reviews_train['label']\n",
    "labels_test = reviews_test['label']\n",
    "\n",
    "reviews_train = reviews_train['text']\n",
    "reviews_test = reviews_test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See one of the elements in the list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I would put this at the top of my list of films in the category of unwatchable trash! There are films that are bad, but the worst kind are the ones that are unwatchable but you are suppose to like them because they are supposed to be good for you! The sex sequences, so shocking in its day, couldn't even arouse a rabbit. The so called controversial politics is strictly high school sophomore amateur night Marxism. The film is self-consciously arty in the worst sense of the term. The photography is in a harsh grainy black and white. Some scenes are out of focus or taken from the wrong angle. Even the sound is bad! And some people call this art?<br /><br />\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reviews_train))\n",
    "print(len(reviews_test))\n",
    "reviews_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw text is pretty messy for these reviews so before we can do any analytics we need to clean things up\n",
    "\n",
    "\n",
    "**Use Regular expressions to remove the non text characters, and the html tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remover todos los signos de puntuación, exclamaciones...\n",
    "# Tb pasamos a minuscula y nos cargamos etiquetas HTML\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    # Para todas las reviews en minuscula, sustituye algunas cosas por espacio y otras por vacio.\n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "# Reviews tras aplicar la limpieza\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i would put this at the top of my list of films in the category of unwatchable trash there are films that are bad but the worst kind are the ones that are unwatchable but you are suppose to like them because they are supposed to be good for you the sex sequences so shocking in its day couldn't even arouse a rabbit the so called controversial politics is strictly high school sophomore amateur night marxism the film is self consciously arty in the worst sense of the term the photography is in a harsh grainy black and white some scenes are out of focus or taken from the wrong angle even the sound is bad and some people call this art \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "In order for this data to make sense to our machine learning algorithm we’ll need to convert each review to a numeric representation, which we call vectorization.\n",
    "\n",
    "The simplest form of this is to create one very large matrix with one column for every unique word in your corpus (where the corpus is all 50k reviews in our case). Then we transform each review into one row containing 0s and 1s, where 1 means that the word in the corpus corresponding to that column appears in that review. That being said, each row of the matrix will be very sparse (mostly zeros). This process is also known as one hot encoding. Use the *CountVectorizer* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Si aparece una palabra en una review, le pone un 1. Da igual que aparezca 100 veces, no cuenta. Xq binary=True\n",
    "# Solo pone 1s cuando detecta una palabra en una review\n",
    "baseline_vectorizer = CountVectorizer(binary=True)\n",
    "baseline_vectorizer.fit(reviews_train_clean)\n",
    "\n",
    "# Reviews en formato vector de palabras. El mismo vectorizador a test, tiene que mantener la estructura\n",
    "X_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
    "X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([86202,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "          172], dtype=int64),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(X_baseline[0].toarray().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(X_baseline[0].toarray().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 86374)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rented': 62973,\n",
       " 'am': 2353,\n",
       " 'curious': 17548,\n",
       " 'yellow': 85603,\n",
       " 'from': 29485,\n",
       " 'my': 51121,\n",
       " 'video': 81913,\n",
       " 'store': 72733,\n",
       " 'because': 6502,\n",
       " 'of': 53454,\n",
       " 'all': 2022,\n",
       " 'the': 76137,\n",
       " 'controversy': 15895,\n",
       " 'that': 76084,\n",
       " 'surrounded': 74215,\n",
       " 'it': 39355,\n",
       " 'when': 83770,\n",
       " 'was': 82973,\n",
       " 'first': 27857,\n",
       " 'released': 62700,\n",
       " 'in': 37458,\n",
       " 'also': 2248,\n",
       " 'heard': 34207,\n",
       " 'at': 4496,\n",
       " 'seized': 67311,\n",
       " 'by': 10595,\n",
       " 'us': 81042,\n",
       " 'customs': 17644,\n",
       " 'if': 36913,\n",
       " 'ever': 25296,\n",
       " 'tried': 78507,\n",
       " 'to': 77311,\n",
       " 'enter': 24467,\n",
       " 'this': 76523,\n",
       " 'country': 16482,\n",
       " 'therefore': 76309,\n",
       " 'being': 6763,\n",
       " 'fan': 26486,\n",
       " 'films': 27599,\n",
       " 'considered': 15577,\n",
       " 'controversial': 15890,\n",
       " 'really': 61803,\n",
       " 'had': 33145,\n",
       " 'see': 67179,\n",
       " 'for': 28638,\n",
       " 'myself': 51153,\n",
       " 'plot': 57943,\n",
       " 'is': 39189,\n",
       " 'centered': 12144,\n",
       " 'around': 3977,\n",
       " 'young': 85803,\n",
       " 'swedish': 74452,\n",
       " 'drama': 22045,\n",
       " 'student': 73191,\n",
       " 'named': 51350,\n",
       " 'lena': 43615,\n",
       " 'who': 83944,\n",
       " 'wants': 82850,\n",
       " 'learn': 43353,\n",
       " 'everything': 25345,\n",
       " 'she': 68179,\n",
       " 'can': 11032,\n",
       " 'about': 284,\n",
       " 'life': 43992,\n",
       " 'particular': 55761,\n",
       " 'focus': 28455,\n",
       " 'her': 34609,\n",
       " 'attentions': 4664,\n",
       " 'making': 46106,\n",
       " 'some': 70638,\n",
       " 'sort': 70880,\n",
       " 'documentary': 21329,\n",
       " 'on': 53798,\n",
       " 'what': 83701,\n",
       " 'average': 4990,\n",
       " 'swede': 74449,\n",
       " 'thought': 76647,\n",
       " 'certain': 12196,\n",
       " 'political': 58257,\n",
       " 'issues': 39333,\n",
       " 'such': 73604,\n",
       " 'as': 4177,\n",
       " 'vietnam': 81969,\n",
       " 'war': 82852,\n",
       " 'and': 2743,\n",
       " 'race': 60978,\n",
       " 'united': 80280,\n",
       " 'states': 72205,\n",
       " 'between': 7297,\n",
       " 'asking': 4270,\n",
       " 'politicians': 58261,\n",
       " 'ordinary': 54223,\n",
       " 'denizens': 19249,\n",
       " 'stockholm': 72634,\n",
       " 'their': 76174,\n",
       " 'opinions': 54072,\n",
       " 'politics': 58267,\n",
       " 'has': 33886,\n",
       " 'sex': 67816,\n",
       " 'with': 84451,\n",
       " 'teacher': 75413,\n",
       " 'classmates': 13755,\n",
       " 'married': 46839,\n",
       " 'men': 48063,\n",
       " 'kills': 41617,\n",
       " 'me': 47642,\n",
       " 'years': 85552,\n",
       " 'ago': 1514,\n",
       " 'pornographic': 58511,\n",
       " 'nudity': 52937,\n",
       " 'scenes': 66343,\n",
       " 'are': 3763,\n",
       " 'few': 27285,\n",
       " 'far': 26609,\n",
       " 'even': 25262,\n",
       " 'then': 76237,\n",
       " 'not': 52704,\n",
       " 'shot': 68639,\n",
       " 'like': 44108,\n",
       " 'cheaply': 12710,\n",
       " 'made': 45787,\n",
       " 'porno': 58507,\n",
       " 'while': 83810,\n",
       " 'countrymen': 16488,\n",
       " 'mind': 48828,\n",
       " 'find': 27709,\n",
       " 'shocking': 68511,\n",
       " 'reality': 61782,\n",
       " 'major': 46060,\n",
       " 'staple': 72070,\n",
       " 'cinema': 13457,\n",
       " 'ingmar': 38117,\n",
       " 'bergman': 7079,\n",
       " 'arguably': 3813,\n",
       " 'answer': 3115,\n",
       " 'good': 31632,\n",
       " 'old': 53693,\n",
       " 'boy': 9088,\n",
       " 'john': 40326,\n",
       " 'ford': 28669,\n",
       " 'his': 35224,\n",
       " 'do': 21262,\n",
       " 'commend': 14744,\n",
       " 'filmmakers': 27573,\n",
       " 'fact': 26232,\n",
       " 'any': 3271,\n",
       " 'shown': 68728,\n",
       " 'film': 27490,\n",
       " 'artistic': 4130,\n",
       " 'purposes': 60489,\n",
       " 'rather': 61509,\n",
       " 'than': 76056,\n",
       " 'just': 40730,\n",
       " 'shock': 68505,\n",
       " 'people': 56426,\n",
       " 'make': 46075,\n",
       " 'money': 49656,\n",
       " 'be': 6343,\n",
       " 'theaters': 76144,\n",
       " 'america': 2484,\n",
       " 'anyone': 3292,\n",
       " 'wanting': 82845,\n",
       " 'study': 73211,\n",
       " 'meat': 47721,\n",
       " 'potatoes': 58702,\n",
       " 'no': 52423,\n",
       " 'pun': 60346,\n",
       " 'intended': 38550,\n",
       " 'but': 10481,\n",
       " 'doesn': 21386,\n",
       " 'have': 34018,\n",
       " 'much': 50653,\n",
       " 'risible': 64134,\n",
       " 'pretentious': 59289,\n",
       " 'steaming': 72301,\n",
       " 'pile': 57370,\n",
       " 'matter': 47233,\n",
       " 'one': 53825,\n",
       " 'views': 81996,\n",
       " 'hardly': 33722,\n",
       " 'taken': 74956,\n",
       " 'seriously': 67666,\n",
       " 'level': 43800,\n",
       " 'claim': 13638,\n",
       " 'frontal': 29494,\n",
       " 'male': 46156,\n",
       " 'an': 2651,\n",
       " 'automatic': 4923,\n",
       " 'nc': 51652,\n",
       " 'isn': 39280,\n",
       " 'true': 78737,\n",
       " 've': 81517,\n",
       " 'seen': 67228,\n",
       " 'rated': 61500,\n",
       " 'granted': 32096,\n",
       " 'they': 76364,\n",
       " 'only': 53917,\n",
       " 'offer': 53491,\n",
       " 'fleeting': 28138,\n",
       " 'where': 83776,\n",
       " 'gaping': 30179,\n",
       " 'vulvas': 82539,\n",
       " 'flapping': 28027,\n",
       " 'labia': 42490,\n",
       " 'nowhere': 52858,\n",
       " 'don': 21559,\n",
       " 'exist': 25701,\n",
       " 'same': 65638,\n",
       " 'goes': 31486,\n",
       " 'those': 76629,\n",
       " 'crappy': 16767,\n",
       " 'cable': 10671,\n",
       " 'shows': 68732,\n",
       " 'schlongs': 66462,\n",
       " 'swinging': 74548,\n",
       " 'breeze': 9410,\n",
       " 'clitoris': 13982,\n",
       " 'sight': 69026,\n",
       " 'indie': 37806,\n",
       " 'movies': 50466,\n",
       " 'brown': 9815,\n",
       " 'bunny': 10255,\n",
       " 'which': 83795,\n",
       " 'we': 83244,\n",
       " 're': 61679,\n",
       " 'treated': 78339,\n",
       " 'site': 69400,\n",
       " 'vincent': 82096,\n",
       " 'gallo': 30034,\n",
       " 'throbbing': 76752,\n",
       " 'johnson': 40341,\n",
       " 'trace': 77947,\n",
       " 'pink': 57453,\n",
       " 'visible': 82234,\n",
       " 'chloe': 13115,\n",
       " 'sevigny': 67801,\n",
       " 'before': 6640,\n",
       " 'crying': 17334,\n",
       " 'or': 54150,\n",
       " 'implying': 37336,\n",
       " 'double': 21825,\n",
       " 'standard': 72023,\n",
       " 'matters': 47236,\n",
       " 'mentally': 48138,\n",
       " 'obtuse': 53299,\n",
       " 'should': 68658,\n",
       " 'take': 74950,\n",
       " 'into': 38832,\n",
       " 'account': 537,\n",
       " 'unavoidably': 79539,\n",
       " 'obvious': 53304,\n",
       " 'anatomical': 2712,\n",
       " 'difference': 20146,\n",
       " 'women': 84631,\n",
       " 'there': 76299,\n",
       " 'genitals': 30584,\n",
       " 'display': 20923,\n",
       " 'actresses': 834,\n",
       " 'appears': 3484,\n",
       " 'nude': 52925,\n",
       " 'cannot': 11132,\n",
       " 'said': 65458,\n",
       " 'man': 46270,\n",
       " 'you': 85772,\n",
       " 'generally': 30535,\n",
       " 'won': 84645,\n",
       " 'female': 27115,\n",
       " 'american': 2492,\n",
       " 'anything': 3299,\n",
       " 'short': 68602,\n",
       " 'porn': 58502,\n",
       " 'explicit': 25869,\n",
       " 'erotica': 24861,\n",
       " 'alleged': 2045,\n",
       " 'less': 43738,\n",
       " 'admittedly': 1041,\n",
       " 'depressing': 19394,\n",
       " 'ability': 226,\n",
       " 'come': 14632,\n",
       " 'terms': 75856,\n",
       " 'culturally': 17480,\n",
       " 'insides': 38333,\n",
       " 'bodies': 8390,\n",
       " 'avoid': 5030,\n",
       " 'type': 79235,\n",
       " 'future': 29813,\n",
       " 'interesting': 38640,\n",
       " 'experiment': 25826,\n",
       " 'tells': 75662,\n",
       " 'cogent': 14318,\n",
       " 'story': 72772,\n",
       " 'might': 48630,\n",
       " 'feel': 27025,\n",
       " 'virtuous': 82197,\n",
       " 'sitting': 69412,\n",
       " 'thru': 76797,\n",
       " 'touches': 77824,\n",
       " 'so': 70372,\n",
       " 'many': 46551,\n",
       " 'important': 37342,\n",
       " 'does': 21380,\n",
       " 'without': 84481,\n",
       " 'discernable': 20590,\n",
       " 'motive': 50217,\n",
       " 'viewer': 81978,\n",
       " 'comes': 14677,\n",
       " 'away': 5085,\n",
       " 'new': 52009,\n",
       " 'perspectives': 56785,\n",
       " 'unless': 80332,\n",
       " 'up': 80850,\n",
       " 'wanders': 82818,\n",
       " 'will': 84168,\n",
       " 'invariably': 38926,\n",
       " 'during': 22708,\n",
       " 'pointless': 58148,\n",
       " 'better': 7260,\n",
       " 'spend': 71324,\n",
       " 'time': 77018,\n",
       " 'staring': 72107,\n",
       " 'out': 54521,\n",
       " 'window': 84276,\n",
       " 'tree': 78358,\n",
       " 'growing': 32597,\n",
       " 'probably': 59506,\n",
       " 'inspired': 38394,\n",
       " 'godard': 31421,\n",
       " 'masculin': 46977,\n",
       " 'féminin': 29854,\n",
       " 'urge': 81004,\n",
       " 'instead': 38424,\n",
       " 'two': 79195,\n",
       " 'strong': 73109,\n",
       " 'elements': 23569,\n",
       " 'realistic': 61767,\n",
       " 'acting': 699,\n",
       " 'impressive': 37397,\n",
       " 'undeservedly': 79914,\n",
       " 'photo': 57136,\n",
       " 'apart': 3357,\n",
       " 'strikes': 73051,\n",
       " 'most': 50159,\n",
       " 'endless': 24163,\n",
       " 'stream': 72962,\n",
       " 'silliness': 69119,\n",
       " 'nyman': 53093,\n",
       " 'annoying': 3058,\n",
       " 'actress': 830,\n",
       " 'world': 84877,\n",
       " 'acts': 841,\n",
       " 'stupid': 73274,\n",
       " 'filmit': 27566,\n",
       " 'unattractive': 79531,\n",
       " 'comparing': 14900,\n",
       " 'intellectuality': 38531,\n",
       " 'been': 6599,\n",
       " 'replaced': 63060,\n",
       " 'stupidity': 73285,\n",
       " 'going': 31510,\n",
       " 'too': 77563,\n",
       " 'subject': 73396,\n",
       " 'would': 84980,\n",
       " 'say': 66111,\n",
       " 'follows': 28535,\n",
       " 'ideals': 36825,\n",
       " 'french': 29292,\n",
       " 'society': 70433,\n",
       " 'movie': 50345,\n",
       " 'its': 39472,\n",
       " 'place': 57633,\n",
       " 'oh': 53592,\n",
       " 'brotherafter': 9786,\n",
       " 'hearing': 34211,\n",
       " 'ridiculous': 63927,\n",
       " 'umpteen': 79454,\n",
       " 'think': 76460,\n",
       " 'peggy': 56298,\n",
       " 'lee': 43440,\n",
       " 'song': 70733,\n",
       " 'early': 22927,\n",
       " 'teen': 75530,\n",
       " 'smoked': 70101,\n",
       " 'fish': 27877,\n",
       " 'hit': 35266,\n",
       " 'get': 30771,\n",
       " 'theater': 76142,\n",
       " 'although': 2299,\n",
       " 'did': 20078,\n",
       " 'manage': 46272,\n",
       " 'sneak': 70222,\n",
       " 'goodbye': 31645,\n",
       " 'columbus': 14584,\n",
       " 'screening': 66799,\n",
       " 'local': 44605,\n",
       " 'museum': 50971,\n",
       " 'beckoned': 6524,\n",
       " 'finally': 27693,\n",
       " 'could': 16405,\n",
       " 'except': 25535,\n",
       " 'now': 52843,\n",
       " 'parents': 55619,\n",
       " 'were': 83581,\n",
       " 'schlepped': 66449,\n",
       " 'reason': 61857,\n",
       " 'condemned': 15242,\n",
       " 'anonymous': 3085,\n",
       " 'sands': 65744,\n",
       " 'obscenity': 53233,\n",
       " 'case': 11633,\n",
       " 'sparked': 71127,\n",
       " 'release': 62697,\n",
       " 'millions': 48779,\n",
       " 'flocked': 28268,\n",
       " 'stinker': 72580,\n",
       " 'thinking': 76469,\n",
       " 'filminstead': 27564,\n",
       " 'got': 31854,\n",
       " 'lots': 45023,\n",
       " 'closeups': 14032,\n",
       " 'gnarly': 31367,\n",
       " 'repulsive': 63178,\n",
       " 'swedes': 74451,\n",
       " 'street': 72975,\n",
       " 'interviews': 38806,\n",
       " 'bland': 7891,\n",
       " 'shopping': 68590,\n",
       " 'malls': 46212,\n",
       " 'asinie': 4258,\n",
       " 'pretensionand': 59283,\n",
       " 'feeble': 27014,\n",
       " 'cares': 11366,\n",
       " 'simulated': 69229,\n",
       " 'saggy': 65441,\n",
       " 'pale': 55267,\n",
       " 'actors': 796,\n",
       " 'cultural': 17478,\n",
       " 'icon': 36795,\n",
       " 'holy': 35576,\n",
       " 'grail': 32017,\n",
       " 'historic': 35243,\n",
       " 'artifactwhatever': 4110,\n",
       " 'thing': 76414,\n",
       " 'shred': 68756,\n",
       " 'burn': 10342,\n",
       " 'stuff': 73214,\n",
       " 'ashes': 4222,\n",
       " 'lead': 43304,\n",
       " 'box': 9073,\n",
       " 'elite': 23635,\n",
       " 'esthetes': 25063,\n",
       " 'still': 72534,\n",
       " 'scrape': 66747,\n",
       " 'value': 81315,\n",
       " 'boring': 8865,\n",
       " 'pseudo': 60105,\n",
       " 'revolutionary': 63704,\n",
       " 'spewingsbut': 71345,\n",
       " 'weren': 83588,\n",
       " 'censorship': 12132,\n",
       " 'scandal': 66204,\n",
       " 'ignored': 36951,\n",
       " 'forgotten': 28785,\n",
       " 'blank': 7905,\n",
       " 'rhythymed': 63817,\n",
       " 'title': 77259,\n",
       " 'repeated': 63020,\n",
       " 'endlessly': 24164,\n",
       " 'titilation': 77251,\n",
       " 'lavender': 43201,\n",
       " 'gay': 30397,\n",
       " 'black': 7768,\n",
       " 'blaxploitation': 7947,\n",
       " 'etc': 25094,\n",
       " 'every': 25333,\n",
       " 'ten': 75718,\n",
       " 'rises': 64131,\n",
       " 'dead': 18361,\n",
       " 'viewed': 81977,\n",
       " 'generation': 30542,\n",
       " 'suckers': 73624,\n",
       " 'want': 82836,\n",
       " 'naughty': 51579,\n",
       " 'revolutionized': 63711,\n",
       " 'industry': 37895,\n",
       " 'yeesh': 85586,\n",
       " 'plagueor': 57682,\n",
       " 'must': 51042,\n",
       " 'rent': 62965,\n",
       " 'fast': 26748,\n",
       " 'forward': 28913,\n",
       " 'dirty': 20482,\n",
       " 'parts': 55795,\n",
       " 'over': 54725,\n",
       " 'put': 60541,\n",
       " 'top': 77629,\n",
       " 'list': 44394,\n",
       " 'category': 11849,\n",
       " 'unwatchable': 80812,\n",
       " 'trash': 78250,\n",
       " 'bad': 5402,\n",
       " 'worst': 84958,\n",
       " 'kind': 41655,\n",
       " 'ones': 53864,\n",
       " 'suppose': 74080,\n",
       " 'them': 76183,\n",
       " 'supposed': 74083,\n",
       " 'sequences': 67576,\n",
       " 'day': 18287,\n",
       " 'couldn': 16409,\n",
       " 'arouse': 3989,\n",
       " 'rabbit': 60960,\n",
       " 'called': 10863,\n",
       " 'strictly': 73032,\n",
       " 'high': 34958,\n",
       " 'school': 66515,\n",
       " 'sophomore': 70825,\n",
       " 'amateur': 2381,\n",
       " 'night': 52238,\n",
       " 'marxism': 46941,\n",
       " 'self': 67336,\n",
       " 'consciously': 15534,\n",
       " 'arty': 4159,\n",
       " 'sense': 67452,\n",
       " 'term': 75838,\n",
       " 'photography': 57152,\n",
       " 'harsh': 33855,\n",
       " 'grainy': 32024,\n",
       " 'white': 83886,\n",
       " 'wrong': 85145,\n",
       " 'angle': 2901,\n",
       " 'sound': 70935,\n",
       " 'call': 10857,\n",
       " 'art': 4064,\n",
       " 'whoever': 83953,\n",
       " 'wrote': 85169,\n",
       " 'screenplay': 66806,\n",
       " 'obviously': 53306,\n",
       " 'never': 51995,\n",
       " 'consulted': 15682,\n",
       " 'books': 8732,\n",
       " 'lucille': 45278,\n",
       " 'ball': 5636,\n",
       " 'especially': 24984,\n",
       " 'autobiography': 4907,\n",
       " 'mistakes': 49266,\n",
       " 'biopic': 7623,\n",
       " 'ranging': 61360,\n",
       " 'celoron': 12108,\n",
       " 'jamestown': 39736,\n",
       " 'later': 43035,\n",
       " 'desi': 19541,\n",
       " 'write': 85113,\n",
       " 'whole': 83956,\n",
       " 'factual': 26257,\n",
       " 'errors': 24881,\n",
       " 'go': 31384,\n",
       " 'pages': 55180,\n",
       " 'believe': 6831,\n",
       " 'inimitable': 38169,\n",
       " 'simply': 69217,\n",
       " 'portrayed': 58571,\n",
       " 'other': 54451,\n",
       " 'themselves': 76218,\n",
       " 'lucie': 45272,\n",
       " 'arnaz': 3951,\n",
       " 'jr': 40547,\n",
       " 'irate': 39079,\n",
       " 'how': 36136,\n",
       " 'hard': 33690,\n",
       " 'seems': 67223,\n",
       " 'awfully': 5127,\n",
       " 'sloppy': 69901,\n",
       " 'saw': 66085,\n",
       " 'glimpse': 31252,\n",
       " 'quickly': 60844,\n",
       " 'noticed': 52751,\n",
       " 'playing': 57820,\n",
       " 'role': 64471,\n",
       " 'rachel': 60994,\n",
       " 'york': 85746,\n",
       " 'portrayal': 58568,\n",
       " 'lucy': 45301,\n",
       " 'absolutely': 347,\n",
       " 'awful': 5121,\n",
       " 'astounding': 4449,\n",
       " 'comedian': 14636,\n",
       " 'incredible': 37692,\n",
       " 'talent': 74994,\n",
       " 'legend': 43500,\n",
       " 'way': 83187,\n",
       " 'horrendous': 35886,\n",
       " 'play': 57791,\n",
       " 'producers': 59602,\n",
       " 'decided': 18606,\n",
       " 'roles': 64483,\n",
       " 'tough': 77838,\n",
       " 'pretty': 59299,\n",
       " 'someone': 70650,\n",
       " 'resemble': 63236,\n",
       " 'least': 43371,\n",
       " 'bit': 7700,\n",
       " 'similar': 69162,\n",
       " 'looks': 44870,\n",
       " 'episodes': 24692,\n",
       " 'love': 45101,\n",
       " 'chocolate': 13127,\n",
       " 'factory': 26250,\n",
       " 'vitavetavegamin': 82286,\n",
       " 'nothing': 52734,\n",
       " 'expression': 25952,\n",
       " 'voice': 82363,\n",
       " 'movement': 50331,\n",
       " 'off': 53464,\n",
       " 'danny': 18041,\n",
       " 'pino': 57471,\n",
       " 'horrible': 35890,\n",
       " 'qualify': 60690,\n",
       " 'ricky': 63890,\n",
       " 'he': 34122,\n",
       " 'small': 70000,\n",
       " 'skinny': 69569,\n",
       " 'accent': 442,\n",
       " 'unreal': 80534,\n",
       " 'once': 53809,\n",
       " 'again': 1389,\n",
       " 'unbelievable': 79566,\n",
       " 'fred': 29216,\n",
       " 'ethel': 25133,\n",
       " 'either': 23437,\n",
       " 'characters': 12504,\n",
       " 'overall': 54739,\n",
       " 'extremely': 26067,\n",
       " 'casting': 11741,\n",
       " 'badly': 5453,\n",
       " 'told': 77429,\n",
       " 'understand': 79859,\n",
       " 'real': 61749,\n",
       " 'situation': 69415,\n",
       " 'suggest': 73707,\n",
       " 'watching': 83075,\n",
       " 'biography': 7615,\n",
       " 'read': 61711,\n",
       " 'book': 8696,\n",
       " 'herself': 34770,\n",
       " 'pbs': 56130,\n",
       " 'masters': 47085,\n",
       " 'finding': 27714,\n",
       " 'docudrama': 21319,\n",
       " 'laughter': 43146,\n",
       " 'choice': 13132,\n",
       " 'compared': 14896,\n",
       " 'aspect': 4283,\n",
       " 'these': 76345,\n",
       " 'certainly': 12197,\n",
       " 'audience': 4740,\n",
       " 'among': 2569,\n",
       " 'air': 1658,\n",
       " 'puffed': 60268,\n",
       " 'productions': 59613,\n",
       " 'existence': 25709,\n",
       " 'lot': 45010,\n",
       " 'fun': 29655,\n",
       " 'shoot': 68560,\n",
       " 'nobody': 52439,\n",
       " 'getting': 30787,\n",
       " 'actual': 845,\n",
       " 'work': 84814,\n",
       " 'done': 21582,\n",
       " 'almost': 2171,\n",
       " 'always': 2335,\n",
       " 'makes': 46093,\n",
       " 'watch': 83052,\n",
       " 'ritter': 64161,\n",
       " 'dons': 21631,\n",
       " 'glasses': 31202,\n",
       " 'hammer': 33422,\n",
       " 'home': 35583,\n",
       " 'character': 12467,\n",
       " 'status': 72241,\n",
       " 'doppleganger': 21719,\n",
       " 'bespectacled': 7185,\n",
       " 'bogdanovich': 8442,\n",
       " 'breezy': 9414,\n",
       " 'ms': 50622,\n",
       " 'stratten': 72942,\n",
       " 'sweet': 74467,\n",
       " 'embarrassing': 23803,\n",
       " 'look': 44847,\n",
       " 'guys': 33005,\n",
       " 'dating': 18211,\n",
       " 'prom': 59759,\n",
       " 'queen': 60770,\n",
       " 'ben': 6930,\n",
       " 'gazzara': 30428,\n",
       " 'sports': 71620,\n",
       " 'usual': 81108,\n",
       " 'cat': 11787,\n",
       " 'canary': 11042,\n",
       " 'grin': 32424,\n",
       " 'futile': 29805,\n",
       " 'attempt': 4639,\n",
       " 'elevate': 23586,\n",
       " 'meager': 47653,\n",
       " 'requires': 63200,\n",
       " 'him': 35078,\n",
       " 'pursue': 60507,\n",
       " 'audrey': 4770,\n",
       " 'hepburn': 34604,\n",
       " 'interest': 38633,\n",
       " 'narcoleptic': 51440,\n",
       " 'insomnia': 38371,\n",
       " 'clinic': 13957,\n",
       " 'meantime': 47706,\n",
       " 'budding': 10024,\n",
       " 'couple': 16501,\n",
       " 'respective': 63357,\n",
       " 'children': 13009,\n",
       " 'nepotism': 51897,\n",
       " 'alert': 1906,\n",
       " 'daughters': 18225,\n",
       " 'spew': 71342,\n",
       " 'cute': 17652,\n",
       " 'pick': 57231,\n",
       " 'fairly': 26339,\n",
       " 'disturbing': 21123,\n",
       " 'pointers': 58143,\n",
       " 'observing': 53262,\n",
       " 'drawing': 22110,\n",
       " 'dignity': 20226,\n",
       " 'manages': 46281,\n",
       " 'rise': 64128,\n",
       " 'above': 305,\n",
       " 'proceedings': 59547,\n",
       " 'monumental': 49838,\n",
       " 'challenge': 12307,\n",
       " 'ostensibly': 54428,\n",
       " 'everybody': 25335,\n",
       " 'great': 32221,\n",
       " 'expect': 25770,\n",
       " 'looking': 44858,\n",
       " 'picking': 57245,\n",
       " 'copy': 16096,\n",
       " 'vogue': 82356,\n",
       " 'mentioned': 48142,\n",
       " 'colleen': 14466,\n",
       " 'camp': 10980,\n",
       " 'thoroughly': 76622,\n",
       " 'annoys': 3068,\n",
       " 'singing': 69280,\n",
       " 'competent': 14947,\n",
       " 'wholly': 83967,\n",
       " 'unconvincing': 79704,\n",
       " 'western': 83624,\n",
       " 'numbers': 52980,\n",
       " 'woefully': 84568,\n",
       " 'mismatched': 49175,\n",
       " 'standards': 72027,\n",
       " 'soundtrack': 70957,\n",
       " 'surely': 74127,\n",
       " 'gershwin': 30751,\n",
       " 'derived': 19450,\n",
       " 'stage': 71913,\n",
       " 'musicals': 50993,\n",
       " 'may': 47337,\n",
       " 'slight': 69817,\n",
       " 'long': 44788,\n",
       " 'charm': 12604,\n",
       " 'laughed': 43121,\n",
       " 'tries': 78511,\n",
       " 'coast': 14179,\n",
       " 'intentions': 38581,\n",
       " 'peter': 56867,\n",
       " 'brakes': 9206,\n",
       " 'due': 22490,\n",
       " 'part': 55728,\n",
       " 'tragic': 78014,\n",
       " 'death': 18447,\n",
       " 'dorothy': 21774,\n",
       " 'special': 71203,\n",
       " 'heart': 34222,\n",
       " 'mr': 50583,\n",
       " 'bought': 8988,\n",
       " 'back': 5309,\n",
       " 'distributed': 21103,\n",
       " 'own': 55025,\n",
       " 'went': 83573,\n",
       " 'bankrupt': 5813,\n",
       " 'didn': 20096,\n",
       " 'prove': 60007,\n",
       " 'popular': 58459,\n",
       " 'fall': 26389,\n",
       " 'more': 49964,\n",
       " 'sympathetic': 74669,\n",
       " 'hollywood': 35529,\n",
       " 'stories': 72749,\n",
       " 'joy': 40522,\n",
       " 'criticizing': 17097,\n",
       " '_is_': 50,\n",
       " 'emotional': 23933,\n",
       " 'investment': 38973,\n",
       " 'faint': 26316,\n",
       " 'echo': 23072,\n",
       " 'last': 43002,\n",
       " 'picture': 57271,\n",
       " 'show': 68689,\n",
       " 'paper': 55467,\n",
       " 'moon': 49860,\n",
       " 'doc': 21285,\n",
       " 'following': 28533,\n",
       " 'daisy': 17861,\n",
       " 'miller': 48759,\n",
       " 'thundering': 76855,\n",
       " 'confirmation': 15345,\n",
       " 'phase': 56979,\n",
       " 'pb': 56127,\n",
       " 'emerged': 23863,\n",
       " 'though': 76635,\n",
       " 'harmless': 33785,\n",
       " 'waste': 83023,\n",
       " 'rental': 62968,\n",
       " 'having': 34036,\n",
       " 'll': 44543,\n",
       " 'park': 55648,\n",
       " 'sunny': 73889,\n",
       " 'filmic': 27556,\n",
       " 'expressions': 25958,\n",
       " 'stick': 72493,\n",
       " 'ernest': 24846,\n",
       " 'lubitsch': 45251,\n",
       " 'jaques': 39820,\n",
       " 'demy': 19209,\n",
       " 'personal': 56757,\n",
       " 'bogdonavitch': 8446,\n",
       " 'based': 6089,\n",
       " 'changed': 12388,\n",
       " 'things': 76438,\n",
       " 'fit': 27909,\n",
       " 'detectives': 19698,\n",
       " 'date': 18201,\n",
       " 'beautiful': 6469,\n",
       " 'models': 49441,\n",
       " 'problem': 59522,\n",
       " 'sounds': 70949,\n",
       " 'millionaire': 48775,\n",
       " 'playboy': 57796,\n",
       " 'filmmaker': 27571,\n",
       " 'detective': 19696,\n",
       " 'entire': 24535,\n",
       " 'written': 85139,\n",
       " 'touch': 77820,\n",
       " 'know': 41989,\n",
       " 'indeed': 37736,\n",
       " 'leaves': 43401,\n",
       " 'bored': 8842,\n",
       " 'confused': 15391,\n",
       " 'jealous': 39927,\n",
       " 'curio': 17545,\n",
       " 'murdered': 50898,\n",
       " 'right': 63988,\n",
       " 'after': 1350,\n",
       " 'filming': 27561,\n",
       " 'patti': 56025,\n",
       " 'hanson': 33597,\n",
       " 'marry': 46852,\n",
       " 'keith': 41268,\n",
       " 'richards': 63856,\n",
       " 'model': 49435,\n",
       " 'ample': 2605,\n",
       " 'seemed': 67216,\n",
       " 'forced': 28657,\n",
       " 'added': 908,\n",
       " 'convoluted': 15970,\n",
       " 'begin': 6684,\n",
       " 'somebody': 70640,\n",
       " 'very': 81774,\n",
       " 'relate': 62662,\n",
       " 'manhattan': 46377,\n",
       " 'supermodels': 73992,\n",
       " 'your': 85829,\n",
       " 'beckon': 6523,\n",
       " 'rest': 63389,\n",
       " 'irritating': 39173,\n",
       " 'snore': 70315,\n",
       " 'fest': 27233,\n",
       " 'happens': 33635,\n",
       " 'entertain': 24478,\n",
       " 'friends': 29393,\n",
       " 'inside': 38329,\n",
       " 'jokes': 40376,\n",
       " 'bore': 8839,\n",
       " 'favorite': 26875,\n",
       " 'stars': 72136,\n",
       " 'including': 37604,\n",
       " 'gazarra': 30417,\n",
       " 'looked': 44851,\n",
       " 'quite': 60909,\n",
       " 'wonderful': 84653,\n",
       " 'given': 31128,\n",
       " 'lines': 44282,\n",
       " 'neither': 51842,\n",
       " 'understood': 79874,\n",
       " 'cared': 11340,\n",
       " 'doing': 21449,\n",
       " 'smaller': 70002,\n",
       " 'fine': 27720,\n",
       " 'patty': 56029,\n",
       " 'henson': 34596,\n",
       " 'confident': 15330,\n",
       " 'sidekick': 68957,\n",
       " 'showed': 68704,\n",
       " 'sad': 65354,\n",
       " 'star': 72076,\n",
       " 'sadly': 65389,\n",
       " 'chance': 12350,\n",
       " 'act': 684,\n",
       " 'fans': 26540,\n",
       " 'open': 54016,\n",
       " 'minded': 48836,\n",
       " 'started': 72156,\n",
       " 'big': 7459,\n",
       " 'enjoyed': 24335,\n",
       " 'meow': 48166,\n",
       " 'targets': 75218,\n",
       " 'nickleodeon': 52167,\n",
       " 'surprised': 74184,\n",
       " 'barely': 5931,\n",
       " 'able': 235,\n",
       " 'keep': 41239,\n",
       " 'awake': 5057,\n",
       " 'ironic': 39109,\n",
       " 'agency': 1443,\n",
       " 'clients': 13905,\n",
       " 'romantically': 64553,\n",
       " 'involved': 39017,\n",
       " 'each': 22887,\n",
       " 'five': 27928,\n",
       " 'ex': 25448,\n",
       " 'girlfriend': 31053,\n",
       " 'cybil': 17705,\n",
       " 'shepherd': 68285,\n",
       " 'television': 75636,\n",
       " 'series': 67645,\n",
       " 'moonlighting': 49869,\n",
       " 'stealing': 72289,\n",
       " 'idea': 36810,\n",
       " 'course': 16521,\n",
       " 'relied': 62735,\n",
       " 'tons': 77557,\n",
       " 'witty': 84518,\n",
       " 'dialogue': 19970,\n",
       " 'slapstick': 69678,\n",
       " 'screwball': 66832,\n",
       " 'bottom': 8976,\n",
       " 'line': 44262,\n",
       " 'ain': 1650,\n",
       " 'version': 81742,\n",
       " 'praising': 58881,\n",
       " 'herein': 34656,\n",
       " 'aren': 3778,\n",
       " 'prepared': 59142,\n",
       " 'possibility': 58635,\n",
       " 'script': 66859,\n",
       " 'lack': 42542,\n",
       " 'thereof': 76320,\n",
       " 'plus': 58045,\n",
       " 'side': 68945,\n",
       " 'general': 30524,\n",
       " 'craft': 16688,\n",
       " 'technical': 75485,\n",
       " 'crew': 16973,\n",
       " 'sow': 71016,\n",
       " 'ear': 22907,\n",
       " 'silk': 69112,\n",
       " 'purse': 60499,\n",
       " 'galaxina': 29987,\n",
       " 'target': 75215,\n",
       " 'cheap': 12698,\n",
       " 'laughs': 43137,\n",
       " 'expense': 25809,\n",
       " 'seem': 67212,\n",
       " 'amazingly': 2411,\n",
       " 'killing': 41610,\n",
       " 'unicorn': 80192,\n",
       " 'cast': 11717,\n",
       " 'bunnies': 10254,\n",
       " 'bob': 8346,\n",
       " 'fosse': 28922,\n",
       " 'whom': 83969,\n",
       " 'obsessed': 53264,\n",
       " 'enough': 24381,\n",
       " 'sister': 69379,\n",
       " 'murder': 50895,\n",
       " 'hands': 33520,\n",
       " 'low': 45178,\n",
       " 'husband': 36545,\n",
       " 'zillion': 86166,\n",
       " 'times': 77078,\n",
       " 'silver': 69133,\n",
       " 'screen': 66787,\n",
       " 'hansen': 33594,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_baseline.shape)\n",
    "\n",
    "# Asigna un numero segun el orden de aparicion\n",
    "baseline_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_c = CountVectorizer()\n",
    "vectorizer_c.fit(reviews_train_clean)\n",
    "\n",
    "# Ya no es binaria la aparicion, sino un conteo por palabra\n",
    "X_baseline_c = vectorizer_c.transform(reviews_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 86374)\n",
      "86374\n"
     ]
    }
   ],
   "source": [
    "print(X_baseline_c.shape)\n",
    "print(len(vectorizer_c.get_feature_names())) # Las mismas\n",
    "#X_baseline_c.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x86374 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3409819 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz demasiado grande como para que numpy la imprima por pantalla\n",
    "X_baseline_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([86202,   129,    22,     9,     5,     1,     2,     0,     1,\n",
       "            3], dtype=int64),\n",
       " array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(X_baseline_c[0].toarray().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  1,  1,  1,  3,  1,  8,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,\n",
       "        2,  1,  1,  1,  1,  3,  1,  1,  1,  1,  1,  2,  1,  2,  1,  1,  1,\n",
       "        1,  1,  1,  3,  1,  2,  1,  2,  1,  4,  1,  1,  2,  2,  1,  1,  1,\n",
       "        2,  1,  1, 10,  1,  1,  4,  2,  6,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  2,  6,\n",
       "        1,  2,  1,  1,  1,  1,  2,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,\n",
       "        1,  3,  1,  1,  2,  1,  1,  5,  3,  1,  1,  1,  3,  2,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  3,  1,  1,  4, 10,  1,  2,  1,  1,  4,\n",
       "        1,  9,  1,  1,  1,  1,  1,  1,  2,  1,  3,  2,  1,  1,  1,  1,  1,\n",
       "        3,  1], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = X_baseline_c[0].toarray().reshape(-1).copy()\n",
    "xb[xb!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "274\n"
     ]
    }
   ],
   "source": [
    "print(len(xb[xb!=0]))\n",
    "print(sum(xb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(xb[xb!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rented': 62973,\n",
       " 'am': 2353,\n",
       " 'curious': 17548,\n",
       " 'yellow': 85603,\n",
       " 'from': 29485,\n",
       " 'my': 51121,\n",
       " 'video': 81913,\n",
       " 'store': 72733,\n",
       " 'because': 6502,\n",
       " 'of': 53454,\n",
       " 'all': 2022,\n",
       " 'the': 76137,\n",
       " 'controversy': 15895,\n",
       " 'that': 76084,\n",
       " 'surrounded': 74215,\n",
       " 'it': 39355,\n",
       " 'when': 83770,\n",
       " 'was': 82973,\n",
       " 'first': 27857,\n",
       " 'released': 62700,\n",
       " 'in': 37458,\n",
       " 'also': 2248,\n",
       " 'heard': 34207,\n",
       " 'at': 4496,\n",
       " 'seized': 67311,\n",
       " 'by': 10595,\n",
       " 'us': 81042,\n",
       " 'customs': 17644,\n",
       " 'if': 36913,\n",
       " 'ever': 25296,\n",
       " 'tried': 78507,\n",
       " 'to': 77311,\n",
       " 'enter': 24467,\n",
       " 'this': 76523,\n",
       " 'country': 16482,\n",
       " 'therefore': 76309,\n",
       " 'being': 6763,\n",
       " 'fan': 26486,\n",
       " 'films': 27599,\n",
       " 'considered': 15577,\n",
       " 'controversial': 15890,\n",
       " 'really': 61803,\n",
       " 'had': 33145,\n",
       " 'see': 67179,\n",
       " 'for': 28638,\n",
       " 'myself': 51153,\n",
       " 'plot': 57943,\n",
       " 'is': 39189,\n",
       " 'centered': 12144,\n",
       " 'around': 3977,\n",
       " 'young': 85803,\n",
       " 'swedish': 74452,\n",
       " 'drama': 22045,\n",
       " 'student': 73191,\n",
       " 'named': 51350,\n",
       " 'lena': 43615,\n",
       " 'who': 83944,\n",
       " 'wants': 82850,\n",
       " 'learn': 43353,\n",
       " 'everything': 25345,\n",
       " 'she': 68179,\n",
       " 'can': 11032,\n",
       " 'about': 284,\n",
       " 'life': 43992,\n",
       " 'particular': 55761,\n",
       " 'focus': 28455,\n",
       " 'her': 34609,\n",
       " 'attentions': 4664,\n",
       " 'making': 46106,\n",
       " 'some': 70638,\n",
       " 'sort': 70880,\n",
       " 'documentary': 21329,\n",
       " 'on': 53798,\n",
       " 'what': 83701,\n",
       " 'average': 4990,\n",
       " 'swede': 74449,\n",
       " 'thought': 76647,\n",
       " 'certain': 12196,\n",
       " 'political': 58257,\n",
       " 'issues': 39333,\n",
       " 'such': 73604,\n",
       " 'as': 4177,\n",
       " 'vietnam': 81969,\n",
       " 'war': 82852,\n",
       " 'and': 2743,\n",
       " 'race': 60978,\n",
       " 'united': 80280,\n",
       " 'states': 72205,\n",
       " 'between': 7297,\n",
       " 'asking': 4270,\n",
       " 'politicians': 58261,\n",
       " 'ordinary': 54223,\n",
       " 'denizens': 19249,\n",
       " 'stockholm': 72634,\n",
       " 'their': 76174,\n",
       " 'opinions': 54072,\n",
       " 'politics': 58267,\n",
       " 'has': 33886,\n",
       " 'sex': 67816,\n",
       " 'with': 84451,\n",
       " 'teacher': 75413,\n",
       " 'classmates': 13755,\n",
       " 'married': 46839,\n",
       " 'men': 48063,\n",
       " 'kills': 41617,\n",
       " 'me': 47642,\n",
       " 'years': 85552,\n",
       " 'ago': 1514,\n",
       " 'pornographic': 58511,\n",
       " 'nudity': 52937,\n",
       " 'scenes': 66343,\n",
       " 'are': 3763,\n",
       " 'few': 27285,\n",
       " 'far': 26609,\n",
       " 'even': 25262,\n",
       " 'then': 76237,\n",
       " 'not': 52704,\n",
       " 'shot': 68639,\n",
       " 'like': 44108,\n",
       " 'cheaply': 12710,\n",
       " 'made': 45787,\n",
       " 'porno': 58507,\n",
       " 'while': 83810,\n",
       " 'countrymen': 16488,\n",
       " 'mind': 48828,\n",
       " 'find': 27709,\n",
       " 'shocking': 68511,\n",
       " 'reality': 61782,\n",
       " 'major': 46060,\n",
       " 'staple': 72070,\n",
       " 'cinema': 13457,\n",
       " 'ingmar': 38117,\n",
       " 'bergman': 7079,\n",
       " 'arguably': 3813,\n",
       " 'answer': 3115,\n",
       " 'good': 31632,\n",
       " 'old': 53693,\n",
       " 'boy': 9088,\n",
       " 'john': 40326,\n",
       " 'ford': 28669,\n",
       " 'his': 35224,\n",
       " 'do': 21262,\n",
       " 'commend': 14744,\n",
       " 'filmmakers': 27573,\n",
       " 'fact': 26232,\n",
       " 'any': 3271,\n",
       " 'shown': 68728,\n",
       " 'film': 27490,\n",
       " 'artistic': 4130,\n",
       " 'purposes': 60489,\n",
       " 'rather': 61509,\n",
       " 'than': 76056,\n",
       " 'just': 40730,\n",
       " 'shock': 68505,\n",
       " 'people': 56426,\n",
       " 'make': 46075,\n",
       " 'money': 49656,\n",
       " 'be': 6343,\n",
       " 'theaters': 76144,\n",
       " 'america': 2484,\n",
       " 'anyone': 3292,\n",
       " 'wanting': 82845,\n",
       " 'study': 73211,\n",
       " 'meat': 47721,\n",
       " 'potatoes': 58702,\n",
       " 'no': 52423,\n",
       " 'pun': 60346,\n",
       " 'intended': 38550,\n",
       " 'but': 10481,\n",
       " 'doesn': 21386,\n",
       " 'have': 34018,\n",
       " 'much': 50653,\n",
       " 'risible': 64134,\n",
       " 'pretentious': 59289,\n",
       " 'steaming': 72301,\n",
       " 'pile': 57370,\n",
       " 'matter': 47233,\n",
       " 'one': 53825,\n",
       " 'views': 81996,\n",
       " 'hardly': 33722,\n",
       " 'taken': 74956,\n",
       " 'seriously': 67666,\n",
       " 'level': 43800,\n",
       " 'claim': 13638,\n",
       " 'frontal': 29494,\n",
       " 'male': 46156,\n",
       " 'an': 2651,\n",
       " 'automatic': 4923,\n",
       " 'nc': 51652,\n",
       " 'isn': 39280,\n",
       " 'true': 78737,\n",
       " 've': 81517,\n",
       " 'seen': 67228,\n",
       " 'rated': 61500,\n",
       " 'granted': 32096,\n",
       " 'they': 76364,\n",
       " 'only': 53917,\n",
       " 'offer': 53491,\n",
       " 'fleeting': 28138,\n",
       " 'where': 83776,\n",
       " 'gaping': 30179,\n",
       " 'vulvas': 82539,\n",
       " 'flapping': 28027,\n",
       " 'labia': 42490,\n",
       " 'nowhere': 52858,\n",
       " 'don': 21559,\n",
       " 'exist': 25701,\n",
       " 'same': 65638,\n",
       " 'goes': 31486,\n",
       " 'those': 76629,\n",
       " 'crappy': 16767,\n",
       " 'cable': 10671,\n",
       " 'shows': 68732,\n",
       " 'schlongs': 66462,\n",
       " 'swinging': 74548,\n",
       " 'breeze': 9410,\n",
       " 'clitoris': 13982,\n",
       " 'sight': 69026,\n",
       " 'indie': 37806,\n",
       " 'movies': 50466,\n",
       " 'brown': 9815,\n",
       " 'bunny': 10255,\n",
       " 'which': 83795,\n",
       " 'we': 83244,\n",
       " 're': 61679,\n",
       " 'treated': 78339,\n",
       " 'site': 69400,\n",
       " 'vincent': 82096,\n",
       " 'gallo': 30034,\n",
       " 'throbbing': 76752,\n",
       " 'johnson': 40341,\n",
       " 'trace': 77947,\n",
       " 'pink': 57453,\n",
       " 'visible': 82234,\n",
       " 'chloe': 13115,\n",
       " 'sevigny': 67801,\n",
       " 'before': 6640,\n",
       " 'crying': 17334,\n",
       " 'or': 54150,\n",
       " 'implying': 37336,\n",
       " 'double': 21825,\n",
       " 'standard': 72023,\n",
       " 'matters': 47236,\n",
       " 'mentally': 48138,\n",
       " 'obtuse': 53299,\n",
       " 'should': 68658,\n",
       " 'take': 74950,\n",
       " 'into': 38832,\n",
       " 'account': 537,\n",
       " 'unavoidably': 79539,\n",
       " 'obvious': 53304,\n",
       " 'anatomical': 2712,\n",
       " 'difference': 20146,\n",
       " 'women': 84631,\n",
       " 'there': 76299,\n",
       " 'genitals': 30584,\n",
       " 'display': 20923,\n",
       " 'actresses': 834,\n",
       " 'appears': 3484,\n",
       " 'nude': 52925,\n",
       " 'cannot': 11132,\n",
       " 'said': 65458,\n",
       " 'man': 46270,\n",
       " 'you': 85772,\n",
       " 'generally': 30535,\n",
       " 'won': 84645,\n",
       " 'female': 27115,\n",
       " 'american': 2492,\n",
       " 'anything': 3299,\n",
       " 'short': 68602,\n",
       " 'porn': 58502,\n",
       " 'explicit': 25869,\n",
       " 'erotica': 24861,\n",
       " 'alleged': 2045,\n",
       " 'less': 43738,\n",
       " 'admittedly': 1041,\n",
       " 'depressing': 19394,\n",
       " 'ability': 226,\n",
       " 'come': 14632,\n",
       " 'terms': 75856,\n",
       " 'culturally': 17480,\n",
       " 'insides': 38333,\n",
       " 'bodies': 8390,\n",
       " 'avoid': 5030,\n",
       " 'type': 79235,\n",
       " 'future': 29813,\n",
       " 'interesting': 38640,\n",
       " 'experiment': 25826,\n",
       " 'tells': 75662,\n",
       " 'cogent': 14318,\n",
       " 'story': 72772,\n",
       " 'might': 48630,\n",
       " 'feel': 27025,\n",
       " 'virtuous': 82197,\n",
       " 'sitting': 69412,\n",
       " 'thru': 76797,\n",
       " 'touches': 77824,\n",
       " 'so': 70372,\n",
       " 'many': 46551,\n",
       " 'important': 37342,\n",
       " 'does': 21380,\n",
       " 'without': 84481,\n",
       " 'discernable': 20590,\n",
       " 'motive': 50217,\n",
       " 'viewer': 81978,\n",
       " 'comes': 14677,\n",
       " 'away': 5085,\n",
       " 'new': 52009,\n",
       " 'perspectives': 56785,\n",
       " 'unless': 80332,\n",
       " 'up': 80850,\n",
       " 'wanders': 82818,\n",
       " 'will': 84168,\n",
       " 'invariably': 38926,\n",
       " 'during': 22708,\n",
       " 'pointless': 58148,\n",
       " 'better': 7260,\n",
       " 'spend': 71324,\n",
       " 'time': 77018,\n",
       " 'staring': 72107,\n",
       " 'out': 54521,\n",
       " 'window': 84276,\n",
       " 'tree': 78358,\n",
       " 'growing': 32597,\n",
       " 'probably': 59506,\n",
       " 'inspired': 38394,\n",
       " 'godard': 31421,\n",
       " 'masculin': 46977,\n",
       " 'féminin': 29854,\n",
       " 'urge': 81004,\n",
       " 'instead': 38424,\n",
       " 'two': 79195,\n",
       " 'strong': 73109,\n",
       " 'elements': 23569,\n",
       " 'realistic': 61767,\n",
       " 'acting': 699,\n",
       " 'impressive': 37397,\n",
       " 'undeservedly': 79914,\n",
       " 'photo': 57136,\n",
       " 'apart': 3357,\n",
       " 'strikes': 73051,\n",
       " 'most': 50159,\n",
       " 'endless': 24163,\n",
       " 'stream': 72962,\n",
       " 'silliness': 69119,\n",
       " 'nyman': 53093,\n",
       " 'annoying': 3058,\n",
       " 'actress': 830,\n",
       " 'world': 84877,\n",
       " 'acts': 841,\n",
       " 'stupid': 73274,\n",
       " 'filmit': 27566,\n",
       " 'unattractive': 79531,\n",
       " 'comparing': 14900,\n",
       " 'intellectuality': 38531,\n",
       " 'been': 6599,\n",
       " 'replaced': 63060,\n",
       " 'stupidity': 73285,\n",
       " 'going': 31510,\n",
       " 'too': 77563,\n",
       " 'subject': 73396,\n",
       " 'would': 84980,\n",
       " 'say': 66111,\n",
       " 'follows': 28535,\n",
       " 'ideals': 36825,\n",
       " 'french': 29292,\n",
       " 'society': 70433,\n",
       " 'movie': 50345,\n",
       " 'its': 39472,\n",
       " 'place': 57633,\n",
       " 'oh': 53592,\n",
       " 'brotherafter': 9786,\n",
       " 'hearing': 34211,\n",
       " 'ridiculous': 63927,\n",
       " 'umpteen': 79454,\n",
       " 'think': 76460,\n",
       " 'peggy': 56298,\n",
       " 'lee': 43440,\n",
       " 'song': 70733,\n",
       " 'early': 22927,\n",
       " 'teen': 75530,\n",
       " 'smoked': 70101,\n",
       " 'fish': 27877,\n",
       " 'hit': 35266,\n",
       " 'get': 30771,\n",
       " 'theater': 76142,\n",
       " 'although': 2299,\n",
       " 'did': 20078,\n",
       " 'manage': 46272,\n",
       " 'sneak': 70222,\n",
       " 'goodbye': 31645,\n",
       " 'columbus': 14584,\n",
       " 'screening': 66799,\n",
       " 'local': 44605,\n",
       " 'museum': 50971,\n",
       " 'beckoned': 6524,\n",
       " 'finally': 27693,\n",
       " 'could': 16405,\n",
       " 'except': 25535,\n",
       " 'now': 52843,\n",
       " 'parents': 55619,\n",
       " 'were': 83581,\n",
       " 'schlepped': 66449,\n",
       " 'reason': 61857,\n",
       " 'condemned': 15242,\n",
       " 'anonymous': 3085,\n",
       " 'sands': 65744,\n",
       " 'obscenity': 53233,\n",
       " 'case': 11633,\n",
       " 'sparked': 71127,\n",
       " 'release': 62697,\n",
       " 'millions': 48779,\n",
       " 'flocked': 28268,\n",
       " 'stinker': 72580,\n",
       " 'thinking': 76469,\n",
       " 'filminstead': 27564,\n",
       " 'got': 31854,\n",
       " 'lots': 45023,\n",
       " 'closeups': 14032,\n",
       " 'gnarly': 31367,\n",
       " 'repulsive': 63178,\n",
       " 'swedes': 74451,\n",
       " 'street': 72975,\n",
       " 'interviews': 38806,\n",
       " 'bland': 7891,\n",
       " 'shopping': 68590,\n",
       " 'malls': 46212,\n",
       " 'asinie': 4258,\n",
       " 'pretensionand': 59283,\n",
       " 'feeble': 27014,\n",
       " 'cares': 11366,\n",
       " 'simulated': 69229,\n",
       " 'saggy': 65441,\n",
       " 'pale': 55267,\n",
       " 'actors': 796,\n",
       " 'cultural': 17478,\n",
       " 'icon': 36795,\n",
       " 'holy': 35576,\n",
       " 'grail': 32017,\n",
       " 'historic': 35243,\n",
       " 'artifactwhatever': 4110,\n",
       " 'thing': 76414,\n",
       " 'shred': 68756,\n",
       " 'burn': 10342,\n",
       " 'stuff': 73214,\n",
       " 'ashes': 4222,\n",
       " 'lead': 43304,\n",
       " 'box': 9073,\n",
       " 'elite': 23635,\n",
       " 'esthetes': 25063,\n",
       " 'still': 72534,\n",
       " 'scrape': 66747,\n",
       " 'value': 81315,\n",
       " 'boring': 8865,\n",
       " 'pseudo': 60105,\n",
       " 'revolutionary': 63704,\n",
       " 'spewingsbut': 71345,\n",
       " 'weren': 83588,\n",
       " 'censorship': 12132,\n",
       " 'scandal': 66204,\n",
       " 'ignored': 36951,\n",
       " 'forgotten': 28785,\n",
       " 'blank': 7905,\n",
       " 'rhythymed': 63817,\n",
       " 'title': 77259,\n",
       " 'repeated': 63020,\n",
       " 'endlessly': 24164,\n",
       " 'titilation': 77251,\n",
       " 'lavender': 43201,\n",
       " 'gay': 30397,\n",
       " 'black': 7768,\n",
       " 'blaxploitation': 7947,\n",
       " 'etc': 25094,\n",
       " 'every': 25333,\n",
       " 'ten': 75718,\n",
       " 'rises': 64131,\n",
       " 'dead': 18361,\n",
       " 'viewed': 81977,\n",
       " 'generation': 30542,\n",
       " 'suckers': 73624,\n",
       " 'want': 82836,\n",
       " 'naughty': 51579,\n",
       " 'revolutionized': 63711,\n",
       " 'industry': 37895,\n",
       " 'yeesh': 85586,\n",
       " 'plagueor': 57682,\n",
       " 'must': 51042,\n",
       " 'rent': 62965,\n",
       " 'fast': 26748,\n",
       " 'forward': 28913,\n",
       " 'dirty': 20482,\n",
       " 'parts': 55795,\n",
       " 'over': 54725,\n",
       " 'put': 60541,\n",
       " 'top': 77629,\n",
       " 'list': 44394,\n",
       " 'category': 11849,\n",
       " 'unwatchable': 80812,\n",
       " 'trash': 78250,\n",
       " 'bad': 5402,\n",
       " 'worst': 84958,\n",
       " 'kind': 41655,\n",
       " 'ones': 53864,\n",
       " 'suppose': 74080,\n",
       " 'them': 76183,\n",
       " 'supposed': 74083,\n",
       " 'sequences': 67576,\n",
       " 'day': 18287,\n",
       " 'couldn': 16409,\n",
       " 'arouse': 3989,\n",
       " 'rabbit': 60960,\n",
       " 'called': 10863,\n",
       " 'strictly': 73032,\n",
       " 'high': 34958,\n",
       " 'school': 66515,\n",
       " 'sophomore': 70825,\n",
       " 'amateur': 2381,\n",
       " 'night': 52238,\n",
       " 'marxism': 46941,\n",
       " 'self': 67336,\n",
       " 'consciously': 15534,\n",
       " 'arty': 4159,\n",
       " 'sense': 67452,\n",
       " 'term': 75838,\n",
       " 'photography': 57152,\n",
       " 'harsh': 33855,\n",
       " 'grainy': 32024,\n",
       " 'white': 83886,\n",
       " 'wrong': 85145,\n",
       " 'angle': 2901,\n",
       " 'sound': 70935,\n",
       " 'call': 10857,\n",
       " 'art': 4064,\n",
       " 'whoever': 83953,\n",
       " 'wrote': 85169,\n",
       " 'screenplay': 66806,\n",
       " 'obviously': 53306,\n",
       " 'never': 51995,\n",
       " 'consulted': 15682,\n",
       " 'books': 8732,\n",
       " 'lucille': 45278,\n",
       " 'ball': 5636,\n",
       " 'especially': 24984,\n",
       " 'autobiography': 4907,\n",
       " 'mistakes': 49266,\n",
       " 'biopic': 7623,\n",
       " 'ranging': 61360,\n",
       " 'celoron': 12108,\n",
       " 'jamestown': 39736,\n",
       " 'later': 43035,\n",
       " 'desi': 19541,\n",
       " 'write': 85113,\n",
       " 'whole': 83956,\n",
       " 'factual': 26257,\n",
       " 'errors': 24881,\n",
       " 'go': 31384,\n",
       " 'pages': 55180,\n",
       " 'believe': 6831,\n",
       " 'inimitable': 38169,\n",
       " 'simply': 69217,\n",
       " 'portrayed': 58571,\n",
       " 'other': 54451,\n",
       " 'themselves': 76218,\n",
       " 'lucie': 45272,\n",
       " 'arnaz': 3951,\n",
       " 'jr': 40547,\n",
       " 'irate': 39079,\n",
       " 'how': 36136,\n",
       " 'hard': 33690,\n",
       " 'seems': 67223,\n",
       " 'awfully': 5127,\n",
       " 'sloppy': 69901,\n",
       " 'saw': 66085,\n",
       " 'glimpse': 31252,\n",
       " 'quickly': 60844,\n",
       " 'noticed': 52751,\n",
       " 'playing': 57820,\n",
       " 'role': 64471,\n",
       " 'rachel': 60994,\n",
       " 'york': 85746,\n",
       " 'portrayal': 58568,\n",
       " 'lucy': 45301,\n",
       " 'absolutely': 347,\n",
       " 'awful': 5121,\n",
       " 'astounding': 4449,\n",
       " 'comedian': 14636,\n",
       " 'incredible': 37692,\n",
       " 'talent': 74994,\n",
       " 'legend': 43500,\n",
       " 'way': 83187,\n",
       " 'horrendous': 35886,\n",
       " 'play': 57791,\n",
       " 'producers': 59602,\n",
       " 'decided': 18606,\n",
       " 'roles': 64483,\n",
       " 'tough': 77838,\n",
       " 'pretty': 59299,\n",
       " 'someone': 70650,\n",
       " 'resemble': 63236,\n",
       " 'least': 43371,\n",
       " 'bit': 7700,\n",
       " 'similar': 69162,\n",
       " 'looks': 44870,\n",
       " 'episodes': 24692,\n",
       " 'love': 45101,\n",
       " 'chocolate': 13127,\n",
       " 'factory': 26250,\n",
       " 'vitavetavegamin': 82286,\n",
       " 'nothing': 52734,\n",
       " 'expression': 25952,\n",
       " 'voice': 82363,\n",
       " 'movement': 50331,\n",
       " 'off': 53464,\n",
       " 'danny': 18041,\n",
       " 'pino': 57471,\n",
       " 'horrible': 35890,\n",
       " 'qualify': 60690,\n",
       " 'ricky': 63890,\n",
       " 'he': 34122,\n",
       " 'small': 70000,\n",
       " 'skinny': 69569,\n",
       " 'accent': 442,\n",
       " 'unreal': 80534,\n",
       " 'once': 53809,\n",
       " 'again': 1389,\n",
       " 'unbelievable': 79566,\n",
       " 'fred': 29216,\n",
       " 'ethel': 25133,\n",
       " 'either': 23437,\n",
       " 'characters': 12504,\n",
       " 'overall': 54739,\n",
       " 'extremely': 26067,\n",
       " 'casting': 11741,\n",
       " 'badly': 5453,\n",
       " 'told': 77429,\n",
       " 'understand': 79859,\n",
       " 'real': 61749,\n",
       " 'situation': 69415,\n",
       " 'suggest': 73707,\n",
       " 'watching': 83075,\n",
       " 'biography': 7615,\n",
       " 'read': 61711,\n",
       " 'book': 8696,\n",
       " 'herself': 34770,\n",
       " 'pbs': 56130,\n",
       " 'masters': 47085,\n",
       " 'finding': 27714,\n",
       " 'docudrama': 21319,\n",
       " 'laughter': 43146,\n",
       " 'choice': 13132,\n",
       " 'compared': 14896,\n",
       " 'aspect': 4283,\n",
       " 'these': 76345,\n",
       " 'certainly': 12197,\n",
       " 'audience': 4740,\n",
       " 'among': 2569,\n",
       " 'air': 1658,\n",
       " 'puffed': 60268,\n",
       " 'productions': 59613,\n",
       " 'existence': 25709,\n",
       " 'lot': 45010,\n",
       " 'fun': 29655,\n",
       " 'shoot': 68560,\n",
       " 'nobody': 52439,\n",
       " 'getting': 30787,\n",
       " 'actual': 845,\n",
       " 'work': 84814,\n",
       " 'done': 21582,\n",
       " 'almost': 2171,\n",
       " 'always': 2335,\n",
       " 'makes': 46093,\n",
       " 'watch': 83052,\n",
       " 'ritter': 64161,\n",
       " 'dons': 21631,\n",
       " 'glasses': 31202,\n",
       " 'hammer': 33422,\n",
       " 'home': 35583,\n",
       " 'character': 12467,\n",
       " 'status': 72241,\n",
       " 'doppleganger': 21719,\n",
       " 'bespectacled': 7185,\n",
       " 'bogdanovich': 8442,\n",
       " 'breezy': 9414,\n",
       " 'ms': 50622,\n",
       " 'stratten': 72942,\n",
       " 'sweet': 74467,\n",
       " 'embarrassing': 23803,\n",
       " 'look': 44847,\n",
       " 'guys': 33005,\n",
       " 'dating': 18211,\n",
       " 'prom': 59759,\n",
       " 'queen': 60770,\n",
       " 'ben': 6930,\n",
       " 'gazzara': 30428,\n",
       " 'sports': 71620,\n",
       " 'usual': 81108,\n",
       " 'cat': 11787,\n",
       " 'canary': 11042,\n",
       " 'grin': 32424,\n",
       " 'futile': 29805,\n",
       " 'attempt': 4639,\n",
       " 'elevate': 23586,\n",
       " 'meager': 47653,\n",
       " 'requires': 63200,\n",
       " 'him': 35078,\n",
       " 'pursue': 60507,\n",
       " 'audrey': 4770,\n",
       " 'hepburn': 34604,\n",
       " 'interest': 38633,\n",
       " 'narcoleptic': 51440,\n",
       " 'insomnia': 38371,\n",
       " 'clinic': 13957,\n",
       " 'meantime': 47706,\n",
       " 'budding': 10024,\n",
       " 'couple': 16501,\n",
       " 'respective': 63357,\n",
       " 'children': 13009,\n",
       " 'nepotism': 51897,\n",
       " 'alert': 1906,\n",
       " 'daughters': 18225,\n",
       " 'spew': 71342,\n",
       " 'cute': 17652,\n",
       " 'pick': 57231,\n",
       " 'fairly': 26339,\n",
       " 'disturbing': 21123,\n",
       " 'pointers': 58143,\n",
       " 'observing': 53262,\n",
       " 'drawing': 22110,\n",
       " 'dignity': 20226,\n",
       " 'manages': 46281,\n",
       " 'rise': 64128,\n",
       " 'above': 305,\n",
       " 'proceedings': 59547,\n",
       " 'monumental': 49838,\n",
       " 'challenge': 12307,\n",
       " 'ostensibly': 54428,\n",
       " 'everybody': 25335,\n",
       " 'great': 32221,\n",
       " 'expect': 25770,\n",
       " 'looking': 44858,\n",
       " 'picking': 57245,\n",
       " 'copy': 16096,\n",
       " 'vogue': 82356,\n",
       " 'mentioned': 48142,\n",
       " 'colleen': 14466,\n",
       " 'camp': 10980,\n",
       " 'thoroughly': 76622,\n",
       " 'annoys': 3068,\n",
       " 'singing': 69280,\n",
       " 'competent': 14947,\n",
       " 'wholly': 83967,\n",
       " 'unconvincing': 79704,\n",
       " 'western': 83624,\n",
       " 'numbers': 52980,\n",
       " 'woefully': 84568,\n",
       " 'mismatched': 49175,\n",
       " 'standards': 72027,\n",
       " 'soundtrack': 70957,\n",
       " 'surely': 74127,\n",
       " 'gershwin': 30751,\n",
       " 'derived': 19450,\n",
       " 'stage': 71913,\n",
       " 'musicals': 50993,\n",
       " 'may': 47337,\n",
       " 'slight': 69817,\n",
       " 'long': 44788,\n",
       " 'charm': 12604,\n",
       " 'laughed': 43121,\n",
       " 'tries': 78511,\n",
       " 'coast': 14179,\n",
       " 'intentions': 38581,\n",
       " 'peter': 56867,\n",
       " 'brakes': 9206,\n",
       " 'due': 22490,\n",
       " 'part': 55728,\n",
       " 'tragic': 78014,\n",
       " 'death': 18447,\n",
       " 'dorothy': 21774,\n",
       " 'special': 71203,\n",
       " 'heart': 34222,\n",
       " 'mr': 50583,\n",
       " 'bought': 8988,\n",
       " 'back': 5309,\n",
       " 'distributed': 21103,\n",
       " 'own': 55025,\n",
       " 'went': 83573,\n",
       " 'bankrupt': 5813,\n",
       " 'didn': 20096,\n",
       " 'prove': 60007,\n",
       " 'popular': 58459,\n",
       " 'fall': 26389,\n",
       " 'more': 49964,\n",
       " 'sympathetic': 74669,\n",
       " 'hollywood': 35529,\n",
       " 'stories': 72749,\n",
       " 'joy': 40522,\n",
       " 'criticizing': 17097,\n",
       " '_is_': 50,\n",
       " 'emotional': 23933,\n",
       " 'investment': 38973,\n",
       " 'faint': 26316,\n",
       " 'echo': 23072,\n",
       " 'last': 43002,\n",
       " 'picture': 57271,\n",
       " 'show': 68689,\n",
       " 'paper': 55467,\n",
       " 'moon': 49860,\n",
       " 'doc': 21285,\n",
       " 'following': 28533,\n",
       " 'daisy': 17861,\n",
       " 'miller': 48759,\n",
       " 'thundering': 76855,\n",
       " 'confirmation': 15345,\n",
       " 'phase': 56979,\n",
       " 'pb': 56127,\n",
       " 'emerged': 23863,\n",
       " 'though': 76635,\n",
       " 'harmless': 33785,\n",
       " 'waste': 83023,\n",
       " 'rental': 62968,\n",
       " 'having': 34036,\n",
       " 'll': 44543,\n",
       " 'park': 55648,\n",
       " 'sunny': 73889,\n",
       " 'filmic': 27556,\n",
       " 'expressions': 25958,\n",
       " 'stick': 72493,\n",
       " 'ernest': 24846,\n",
       " 'lubitsch': 45251,\n",
       " 'jaques': 39820,\n",
       " 'demy': 19209,\n",
       " 'personal': 56757,\n",
       " 'bogdonavitch': 8446,\n",
       " 'based': 6089,\n",
       " 'changed': 12388,\n",
       " 'things': 76438,\n",
       " 'fit': 27909,\n",
       " 'detectives': 19698,\n",
       " 'date': 18201,\n",
       " 'beautiful': 6469,\n",
       " 'models': 49441,\n",
       " 'problem': 59522,\n",
       " 'sounds': 70949,\n",
       " 'millionaire': 48775,\n",
       " 'playboy': 57796,\n",
       " 'filmmaker': 27571,\n",
       " 'detective': 19696,\n",
       " 'entire': 24535,\n",
       " 'written': 85139,\n",
       " 'touch': 77820,\n",
       " 'know': 41989,\n",
       " 'indeed': 37736,\n",
       " 'leaves': 43401,\n",
       " 'bored': 8842,\n",
       " 'confused': 15391,\n",
       " 'jealous': 39927,\n",
       " 'curio': 17545,\n",
       " 'murdered': 50898,\n",
       " 'right': 63988,\n",
       " 'after': 1350,\n",
       " 'filming': 27561,\n",
       " 'patti': 56025,\n",
       " 'hanson': 33597,\n",
       " 'marry': 46852,\n",
       " 'keith': 41268,\n",
       " 'richards': 63856,\n",
       " 'model': 49435,\n",
       " 'ample': 2605,\n",
       " 'seemed': 67216,\n",
       " 'forced': 28657,\n",
       " 'added': 908,\n",
       " 'convoluted': 15970,\n",
       " 'begin': 6684,\n",
       " 'somebody': 70640,\n",
       " 'very': 81774,\n",
       " 'relate': 62662,\n",
       " 'manhattan': 46377,\n",
       " 'supermodels': 73992,\n",
       " 'your': 85829,\n",
       " 'beckon': 6523,\n",
       " 'rest': 63389,\n",
       " 'irritating': 39173,\n",
       " 'snore': 70315,\n",
       " 'fest': 27233,\n",
       " 'happens': 33635,\n",
       " 'entertain': 24478,\n",
       " 'friends': 29393,\n",
       " 'inside': 38329,\n",
       " 'jokes': 40376,\n",
       " 'bore': 8839,\n",
       " 'favorite': 26875,\n",
       " 'stars': 72136,\n",
       " 'including': 37604,\n",
       " 'gazarra': 30417,\n",
       " 'looked': 44851,\n",
       " 'quite': 60909,\n",
       " 'wonderful': 84653,\n",
       " 'given': 31128,\n",
       " 'lines': 44282,\n",
       " 'neither': 51842,\n",
       " 'understood': 79874,\n",
       " 'cared': 11340,\n",
       " 'doing': 21449,\n",
       " 'smaller': 70002,\n",
       " 'fine': 27720,\n",
       " 'patty': 56029,\n",
       " 'henson': 34596,\n",
       " 'confident': 15330,\n",
       " 'sidekick': 68957,\n",
       " 'showed': 68704,\n",
       " 'sad': 65354,\n",
       " 'star': 72076,\n",
       " 'sadly': 65389,\n",
       " 'chance': 12350,\n",
       " 'act': 684,\n",
       " 'fans': 26540,\n",
       " 'open': 54016,\n",
       " 'minded': 48836,\n",
       " 'started': 72156,\n",
       " 'big': 7459,\n",
       " 'enjoyed': 24335,\n",
       " 'meow': 48166,\n",
       " 'targets': 75218,\n",
       " 'nickleodeon': 52167,\n",
       " 'surprised': 74184,\n",
       " 'barely': 5931,\n",
       " 'able': 235,\n",
       " 'keep': 41239,\n",
       " 'awake': 5057,\n",
       " 'ironic': 39109,\n",
       " 'agency': 1443,\n",
       " 'clients': 13905,\n",
       " 'romantically': 64553,\n",
       " 'involved': 39017,\n",
       " 'each': 22887,\n",
       " 'five': 27928,\n",
       " 'ex': 25448,\n",
       " 'girlfriend': 31053,\n",
       " 'cybil': 17705,\n",
       " 'shepherd': 68285,\n",
       " 'television': 75636,\n",
       " 'series': 67645,\n",
       " 'moonlighting': 49869,\n",
       " 'stealing': 72289,\n",
       " 'idea': 36810,\n",
       " 'course': 16521,\n",
       " 'relied': 62735,\n",
       " 'tons': 77557,\n",
       " 'witty': 84518,\n",
       " 'dialogue': 19970,\n",
       " 'slapstick': 69678,\n",
       " 'screwball': 66832,\n",
       " 'bottom': 8976,\n",
       " 'line': 44262,\n",
       " 'ain': 1650,\n",
       " 'version': 81742,\n",
       " 'praising': 58881,\n",
       " 'herein': 34656,\n",
       " 'aren': 3778,\n",
       " 'prepared': 59142,\n",
       " 'possibility': 58635,\n",
       " 'script': 66859,\n",
       " 'lack': 42542,\n",
       " 'thereof': 76320,\n",
       " 'plus': 58045,\n",
       " 'side': 68945,\n",
       " 'general': 30524,\n",
       " 'craft': 16688,\n",
       " 'technical': 75485,\n",
       " 'crew': 16973,\n",
       " 'sow': 71016,\n",
       " 'ear': 22907,\n",
       " 'silk': 69112,\n",
       " 'purse': 60499,\n",
       " 'galaxina': 29987,\n",
       " 'target': 75215,\n",
       " 'cheap': 12698,\n",
       " 'laughs': 43137,\n",
       " 'expense': 25809,\n",
       " 'seem': 67212,\n",
       " 'amazingly': 2411,\n",
       " 'killing': 41610,\n",
       " 'unicorn': 80192,\n",
       " 'cast': 11717,\n",
       " 'bunnies': 10254,\n",
       " 'bob': 8346,\n",
       " 'fosse': 28922,\n",
       " 'whom': 83969,\n",
       " 'obsessed': 53264,\n",
       " 'enough': 24381,\n",
       " 'sister': 69379,\n",
       " 'murder': 50895,\n",
       " 'hands': 33520,\n",
       " 'low': 45178,\n",
       " 'husband': 36545,\n",
       " 'zillion': 86166,\n",
       " 'times': 77078,\n",
       " 'silver': 69133,\n",
       " 'screen': 66787,\n",
       " 'hansen': 33594,\n",
       " ...}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_c.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Baseline Model\n",
    "\n",
    "Train a Logistic Regression model after transforming the data with CountVectorized\n",
    "\n",
    "* They’re easy to interpret\n",
    "* Linear models tend to perform well on sparse datasets like this one\n",
    "* They learn very fast compared to other algorithms.\n",
    "\n",
    "Test models with C values of [0.01, 0.05, 0.25, 0.5, 1] and see wich is the best value for C, and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Los comentarios vienen ordenados. Los primeros 12,5k son negativos\n",
    "# A test le ocurre lo mismo\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "\n",
    "def train_model(X_TRAIN, X_TEST):\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    params = {\n",
    "        'C': [0.01, 0.05, 0.25, 0.5, 1]\n",
    "    }\n",
    "    \n",
    "    grid = GridSearchCV(lr, params, cv=5)\n",
    "    grid.fit(X_TRAIN, target)\n",
    "\n",
    "    print (\"Final Accuracy: %s\" % accuracy_score(target, grid.best_estimator_.predict(X_TEST)))\n",
    "    \n",
    "train_model(X_baseline, X_test_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stop Words\n",
    "\n",
    "Stop words are the very common words like ‘if’, ‘but’, ‘we’, ‘he’, ‘she’, and ‘they’. We can usually remove these words without changing the semantics of a text and doing so often (but not always) improves the performance of a model. Removing these stop words becomes a lot more useful when we start using longer word sequences as model features (see n-grams below).\n",
    "\n",
    "Before we apply the CountVectorized, lets remove the stopwords, included in nltk.corpus\n",
    "\n",
    "Then apply the CountVectorizer, and train the Logistic regression model and obtain the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hay que bajarse las stopwords de nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para visualizar los stopwords de inglés\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 313)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english')), len(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para visualizarlas en español\n",
    "stopwords.words('spanish')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Aplicamos la eliminacion de las palabras directamente sobre las reviews\n",
    "# Demasiado manual. Mejor sobre el CountVectorizer (ver abajo)\n",
    "english_stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        \n",
    "        # Para cada review elimina las stopwords, y separa todas las palabras por espacio\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() if word not in english_stop_words])\n",
    "        )\n",
    "        \n",
    "    return removed_stop_words\n",
    "\n",
    "# Se lo aplicamos antes de vectorizar\n",
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87968\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Vectorizamos tras eliminar las stop words\n",
    "Ver docu, tiene cosas interesantes como lowercase=True. Lo hace antes de vectorizar, \n",
    "o el argumento stopwords\n",
    "'''\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(no_stop_words_train)\n",
    "\n",
    "X = cv.transform(no_stop_words_train)\n",
    "\n",
    "# Se aplica el mismo a test\n",
    "X_test = cv.transform(no_stop_words_test)\n",
    "\n",
    "# Y entrenamos\n",
    "train_model(X, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 86374)\n",
      "(25000, 86357)\n",
      "Stop words eliminadas: 17\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X_baseline tras aplicar el vectorizador tal cual en los datos\n",
    "X tras aplicar el vectorizador despues de eliminar las stop words. No se carga muchas\n",
    "'''\n",
    "print(X_baseline.shape)\n",
    "print(X.shape)\n",
    "print(\"Stop words eliminadas:\", X_baseline.shape[1] - X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "El resultado de este codigo es practicamente igual que el anterior, pero elimina mas stopwords\n",
    "'''\n",
    "\n",
    "cv = CountVectorizer(binary=True,\n",
    "                     stop_words = english_stop_words)\n",
    "\n",
    "cv.fit(reviews_train_clean)\n",
    "\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)\n",
    "\n",
    "train_model(X, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 86374)\n",
      "(25000, 86229)\n",
      "Stop words eliminadas: 145\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X_baseline tras aplicar el vectorizador tal cual en los datos\n",
    "X tras aplicar el vectorizador despues de eliminar las stop words\n",
    "En este caso elimina mas, tiene pinta de xq el countvectorizer tokeniza mejor las palabras\n",
    "de lo que lo hemos hecho nosotros en la funcion remove_stop_words. Por ejemplo \"it's\" serian dos palabras\n",
    "'''\n",
    "print(X_baseline.shape)\n",
    "print(X.shape)\n",
    "print(\"Stop words eliminadas:\", X_baseline.shape[1] - X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In practice, an easier way to remove stop words is to just use the stop_words argument with any of scikit-learn’s ‘Vectorizer’ classes. If you want to use NLTK’s full list of stop words you can do stop_words='english’. In practice I’ve found that using NLTK’s list actually decreases my performance because its too expansive, so I usually supply my own list of words. For example, stop_words=['in','of','at','a','the'] ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common next step in text preprocessing is to normalize the words in your corpus by trying to convert all of the different forms of a given word into one. Two methods that exist for this are Stemming and Lemmatization.\n",
    "\n",
    "# Stemming\n",
    "\n",
    "https://www.geeksforgeeks.org/snowball-stemmer-nlp/\n",
    "\n",
    "Stemming is considered to be the more crude/brute-force approach to normalization (although this doesn’t necessarily mean that it will perform worse). There’s several algorithms, but in general they all use basic rules to chop off the ends of words.\n",
    "\n",
    "NLTK has several stemming algorithm implementations. We’ll use the Porter stemmer. Most used:\n",
    "* PorterStemmer\n",
    "* SnowballStemmer\n",
    "\n",
    "Apply a PoterStemmer, vectorize, and train the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress fli die mule deni die agre own humbl size meet state siez item sensat tradit refer colon plot\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "El stemmer se aplica sobre cada palabra. Las recorta eliminando plurales y tiempos verbales\n",
    "Modifica muy poco cada palabra\n",
    "'''\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "            'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "            'meeting', 'stating', 'siezing', 'itemization',\n",
    "            'sensational', 'traditional', 'reference', 'colonizer',\n",
    "            'plotted']\n",
    "singles = [stemmer.stem(plural) for plural in plurals]\n",
    "\n",
    "print(' '.join(singles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress fli die mule deni die agre own humbl size meet state siez item sensat tradit refer colon plot\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "            'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "            'meeting', 'stating', 'siezing', 'itemization',\n",
    "            'sensational', 'traditional', 'reference', 'colonizer',\n",
    "            'plotted']\n",
    "singles = [stemmer.stem(plural) for plural in plurals]\n",
    "\n",
    "print(' '.join(singles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr cas play vol vol volv\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "plurals = ['corriendo', 'casas', 'playa', 'volando', 'volar', 'volveré']\n",
    "singles = [stemmer.stem(plural) for plural in plurals]\n",
    "\n",
    "print(' '.join(singles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87688\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos a mano. Los stemmers no eliminan palabras, solo quitan sufijos, y ahora habrá más palabras que sean iguales\n",
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True, stop_words = english_stop_words)\n",
    "cv.fit(stemmed_reviews_train)\n",
    "\n",
    "X_stem = cv.transform(stemmed_reviews_train)\n",
    "X_test = cv.transform(stemmed_reviews_test)\n",
    "\n",
    "train_model(X_stem, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 86374)\n",
      "(25000, 66083)\n",
      "Diff X normal y X tras stemmer y vectorización: 20291\n"
     ]
    }
   ],
   "source": [
    "# No elimina palabras. Solo recorta sufijos y agrupa tipos de palabras.\n",
    "# Como resultado dará menos palabras debido al agrupado. Se carga unas cuantas letras de las palabras\n",
    "print(X_baseline.shape)\n",
    "print(X_stem.shape)\n",
    "print(\"Diff X normal y X tras stemmer y vectorización:\", X_baseline.shape[1] - X_stem.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "Lemmatization works by identifying the part-of-speech of a given word and then applying more complex rules to transform the word into its true root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daney\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress fly dy mule study died agreed owned humbled sized meeting stating siezing itemization sensational traditional reference colonizer plotted\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "La diferencia con el stemming es que la lematización tiene en cuenta la morfología\n",
    "de la palabra, sustituyendola por la raiz, no recortándola. Y no es tan restrictivo como el stemming.\n",
    "Necesita un buen diccionario con mapeos, como wordnet\n",
    "\n",
    "En nltk no hay lematizadores en español. Habria que bajarse algun paquete como pip install es-lemmatizer\n",
    "'''\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'studies',\n",
    "            'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "            'meeting', 'stating', 'siezing', 'itemization',\n",
    "            'sensational', 'traditional', 'reference', 'colonizer',\n",
    "            'plotted']\n",
    "singles = [lemmatizer.lemmatize(plural) for plural in plurals]\n",
    "\n",
    "print(' '.join(singles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87812\n"
     ]
    }
   ],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "# Lematizamos las reviews\n",
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)\n",
    "\n",
    "# Vectorizamos con conteo tras lematizar\n",
    "cv = CountVectorizer(binary=True, stop_words = english_stop_words)\n",
    "cv.fit(lemmatized_reviews_train)\n",
    "\n",
    "X = cv.transform(lemmatized_reviews_train)\n",
    "X_test = cv.transform(lemmatized_reviews_test)\n",
    "\n",
    "train_model(X, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 87063)\n",
      "(25000, 80181)\n",
      "Diff X normal y X tras lematizador y vectorización: 6882\n"
     ]
    }
   ],
   "source": [
    "# Elimina menos que con el stemmer. Normal, el stemmer recorta mucho del sufijo\n",
    "print(X_baseline.shape)\n",
    "print(X.shape)\n",
    "print(\"Diff X normal y X tras lematizador y vectorización:\", X_baseline.shape[1] - X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams\n",
    "\n",
    "We can potentially add more predictive power to our model by adding two or three word sequences (bigrams or trigrams) as well. For example, if a review had the three word sequence “didn’t love movie” we would only consider these words individually with a unigram-only model and probably not capture that this is actually a negative sentiment because the word ‘love’ by itself is going to be highly correlated with a positive review.\n",
    "\n",
    "The scikit-learn library makes this really easy to play around with. Just use the ngram_range argument with any of the ‘Vectorizer’ classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('this', 'is')\n",
      "('is', 'foo')\n",
      "('foo', 'bar')\n",
      "###############\n",
      "('this', 'is', 'foo')\n",
      "('is', 'foo', 'bar')\n",
      "[[1 1 1 1 1 1 1 1 1]]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "sentence = 'this is foo bar'\n",
    "\n",
    "two = ngrams(sentence.split(), 2)\n",
    "three = ngrams(sentence.split(), 3)\n",
    "\n",
    "for grams in two:\n",
    "  print(grams)\n",
    "print('###############')\n",
    "for grams in three:\n",
    "  print(grams)\n",
    "\n",
    "'''\n",
    "Puede ser bigramas si ngram_range=(2,2), o trigramas (3,3)...\n",
    "Algunas palabras las elimina, como 'a'. Cuidado con eso a la hora de hacer el conteo\n",
    "ngram_range=(1, 3) significa las palabras por separado, los bigramas y los trigramas\n",
    "Ojo que esto aumenta muchisimo el espacio de features\n",
    "'''\n",
    "ngram_vectorizer = CountVectorizer(binary=True,\n",
    "                                   ngram_range=(1, 3))\n",
    "\n",
    "vector = ngram_vectorizer.fit_transform([sentence]).toarray()\n",
    "print(vector)\n",
    "print(len(vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.889\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Va como argumento del CountVectorizer\n",
    "'''\n",
    "ngram_vectorizer = CountVectorizer(binary=True, stop_words = english_stop_words,\n",
    "                                   ngram_range=(1, 2))\n",
    "\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "train_model(X, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 87063)\n",
      "(25000, 1865232)\n",
      "Diff X normal y X tras lematizador y vectorización: -1778169\n"
     ]
    }
   ],
   "source": [
    "# Añade 1448047 n gramas. Cuanto mas ngramas, mayor será el espacio de features\n",
    "print(X_baseline.shape)\n",
    "print(X.shape)\n",
    "print(\"Diff X normal y X tras lematizador y vectorización:\", X_baseline.shape[1] - X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "Another common way to represent each document in a corpus is to use the tf-idf statistic (term frequency-inverse document frequency) for each word, which is a weighting factor that we can use in place of binary or word count representations.\n",
    "\n",
    "There are several ways to do tf-idf transformation but in a nutshell, **tf-idf aims to represent the number of times a given word appears in a document (a movie review in our case) relative to the number of documents in the corpus that the word appears in**.\n",
    "\n",
    "**Note:** Now that we’ve gone over n-grams, when I refer to ‘words’ I really mean any n-gram (sequence of words) if the model is using an n greater than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2876820724517808"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ln(N + 1 / df + 1) + 1\n",
    "Cuanto mas comun, menor es el TDFIDF. Cuanto mas rara, mayor\n",
    "'''\n",
    "# Numero de documentos\n",
    "N = 3\n",
    "\n",
    "# Numero de veces que aparece\n",
    "df = 2\n",
    "\n",
    "1 + np.log((N + 1)/(df + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.69314718 1.28768207 1.69314718 1.69314718 1.        ]\n",
      "['fat', 'is', 'my', 'name', 'ralph']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# TfidfTransformer\n",
    "'''\n",
    "Cuanto mas comun, mas bajo es el TfidfVectorizer\n",
    "'''\n",
    "sent1 = 'My name is Ralph'\n",
    "sent2 = 'Ralph is fat'\n",
    "sent3 = 'Ralph'\n",
    "\n",
    "test = TfidfVectorizer()\n",
    "test.fit_transform([sent1, sent2, sent3])\n",
    "print(test.idf_)\n",
    "print(test.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "\n",
    "train_model(X, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "Recall that linear classifiers tend to work well on very sparse datasets (like the one we have). Another algorithm that can produce great results with a quick training time are Support Vector Machines with a linear kernel.\n",
    "\n",
    "Build a model with an n-gram range from 1 to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SVM con bigramas\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "\n",
    "\n",
    "def train_model_svm(X_TRAIN, X_TEST):\n",
    "    \n",
    "    svm = LinearSVC()\n",
    "    \n",
    "    params = {\n",
    "        'C': [0.01, 0.05, 0.25, 0.5, 1]\n",
    "    }\n",
    "    \n",
    "    grid = GridSearchCV(svm, params, cv=5)\n",
    "    grid.fit(X_TRAIN, target)\n",
    "\n",
    "    print (\"Final Accuracy: %s\" % accuracy_score(target, grid.best_estimator_.predict(X_TEST)))\n",
    "    \n",
    "\n",
    "train_model_svm(X, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model\n",
    "\n",
    "Removing a small set of stop words along with an n-gram range from 1 to 3 and a linear support vector classifier shows the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "ngram_vectorizer = CountVectorizer(binary=True,\n",
    "                                   ngram_range=(1, 3),\n",
    "                                   stop_words=stop_words)\n",
    "\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "train_model(X, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Postitive and Negative Features\n",
    "\n",
    "Obtain the most important features of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87063\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "\n",
    "log_reg = LogisticRegression(C=0.5)\n",
    "log_reg.fit(X, target)\n",
    "\n",
    "# Importancia de los coeficientes. En total, todas las palabras vectorizadas\n",
    "print(len(log_reg.coef_[0]))\n",
    "\n",
    "# Cada coeficiente va asociado a una palabra\n",
    "cv.get_feature_names()\n",
    "\n",
    "# Montamos un diccionario con palabra -> coeficiente\n",
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), log_reg.coef_[0]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 1.3796015137688178)\n",
      "('refreshing', 1.2806374144444463)\n",
      "('perfect', 1.2012611851223425)\n",
      "('superb', 1.1357241728322187)\n",
      "('appreciated', 1.1339191120163457)\n",
      "################################\n",
      "('worst', -2.061496946266291)\n",
      "('waste', -1.9184173016299815)\n",
      "('disappointment', -1.6761904512261208)\n",
      "('poorly', -1.657993242508792)\n",
      "('awful', -1.5348355436989127)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print(best_positive)\n",
    "    \n",
    "print('################################')\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print(best_negative)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy: 86.22%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY GRID SEARCH AND PIPELINES!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8ee907ad2201c6d9588d3f44c3076f7bb061a669037d938a152617689572a16"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
